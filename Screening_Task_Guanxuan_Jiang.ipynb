{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1yhf72V7HCwKZOjBd-Vq0cMjwMYIOVtCx",
      "authorship_tag": "ABX9TyPGpXvzNAPbk+yXcnv211uL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jgxuann/Screening-Task/blob/main/Screening_Task_Guanxuan_Jiang.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Please proceed sequentially to ensure version consistency. Additionally, update your API and Google Drive addresses. If you wish to use my API, please keep it confidential and refrain from misuse. Thank you. Plase change your actual PATH, please contact me if you have any issuses during run my code.***"
      ],
      "metadata": {
        "id": "Pgu26h7EUqOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Please use this version\n",
        "!pip install openai==0.28"
      ],
      "metadata": {
        "collapsed": true,
        "id": "4iHrW8AQlnUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Please use your google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "WAldoD59Ylvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dowload\n",
        "!apt-get update\n",
        "!apt-get install -y unrar tesseract-ocr\n",
        "!apt-get install tesseract-ocr\n",
        "!pip install openai pandas tqdm PyMuPDF pdfminer.six pytesseract pdf2image\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install -y tesseract-ocr-chi-sim\n",
        "!sudo apt-get install -y tesseract-ocr-eng\n",
        "!sudo apt-get install -y poppler-utils\n",
        "!pip install PyPDF2\n",
        "!pip install openai\n",
        "!pip install pandas"
      ],
      "metadata": {
        "collapsed": true,
        "id": "1ViWPCsRplEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Unzip\n",
        "os.makedirs('/content/papers', exist_ok=True)\n",
        "\n",
        "# Set .rar file path\n",
        "rar_file_path = '/content/drive/MyDrive/32 article.rar'  # Change the value based on the actual path\n",
        "\n",
        "# Unzip the RAR file to the 'papers' directory\n",
        "!unrar x \"{rar_file_path}\" /content/papers/\n",
        "\n",
        "# Lists all files in the 'papers/32 article' directory\n",
        "for filename in os.listdir('/content/papers/32 article'):\n",
        "    print(filename)\n"
      ],
      "metadata": {
        "id": "uFRFNnShW8-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import PyPDF2\n",
        "import openai\n",
        "import pandas as pd\n",
        "import json\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "# Set up the OpenAI API key, please use your own API key\n",
        "# I am willing to let you use my test, but please do not abuse it\n",
        "os.environ['OPENAI_API_KEY'] = 'sk-ahpAfeRW2xZh0Cg7144a0f8cC31d4e689d5aDb05E0BdC830'\n",
        "os.environ['OPENAI_BASE_URL'] = \"https://vip.yi-zhan.top/v1\"\n",
        "\n",
        "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
        "openai.api_base = os.getenv('OPENAI_BASE_URL')"
      ],
      "metadata": {
        "id": "MTuUcPgXN6Hq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "# Path\n",
        "pdf_folder_path = '/content/papers/32 article'\n",
        "\n",
        "# Define the function to extract text from a PDF\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    try:\n",
        "        with open(pdf_path, 'rb') as file:\n",
        "            reader = PyPDF2.PdfReader(file)\n",
        "            text = \"\"\n",
        "            for page in reader.pages:\n",
        "                page_text = page.extract_text()\n",
        "                if page_text:\n",
        "                    text += page_text\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading {pdf_path}: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "# Define the function to extract information using OpenAI\n",
        "def extract_information(text):\n",
        "    prompt = f\"\"\"\n",
        "    Please extract the following ten key points from the given research article text and return them in a structured JSON format:\n",
        "\n",
        "    1. Context: Specify whether the study is focused on a specific industry, task or a broader, conceptual scope.\n",
        "    2. Research Question and Findings: Identify the main research question and summarize the key findings.\n",
        "    3. Theme of Research:\n",
        "        a. Human vs. AI: Highlight the comparative advantages between humans and AI, including any conditional outcomes or superiority in specific contexts.\n",
        "        b. Human + AI Collaboration: Specify the types of collaboration discussed, such as the roles of humans and AI, and the sequence of their actions in the process.\n",
        "    4. Method: Classify the research method into one of the following three categories:\n",
        "        a. Conceptual/Case Study\n",
        "        b. Modeling (including stylized or Operations Research (OR) models)\n",
        "        c. Empirical Research (laboratory/field experiments or secondary data analysis)\n",
        "    5. Contribution: Determine the main contribution of the research, categorizing it as theoretical, managerial, or methodological.\n",
        "    6. Future Potential and Limitations: Summarize the recommendations for future research directions or the limitations of the study.\n",
        "    7. Keywords: Conclude the key words.\n",
        "    8. Authors: List all authors.\n",
        "    9. Publication Information: Find the Jornal/Conference infomation(pages,name and so on) and years.\n",
        "    10. Article Name: List the name of the article\n",
        "\n",
        "    Here is the text of the research article:\n",
        "    {text}\n",
        "\n",
        "    Please provide the extracted information in pure JSON format without any code blocks, comments, or additional text:\n",
        "\n",
        "    {{\n",
        "        \"Context\": \"\",\n",
        "        \"Research Question and Findings\": \"\",\n",
        "        \"Theme of Research\": {{\n",
        "            \"Human vs AI\": \"\",\n",
        "            \"Human + AI Collaboration\": \"\"\n",
        "        }},\n",
        "        \"Method\": \"\",\n",
        "        \"Contribution\": \"\",\n",
        "        \"Future Potential and Limitations\": \"\",\n",
        "        \"Keywords\":\"\",\n",
        "        \"Authors\":\"\",\n",
        "        \"Publication Information\":\"\",\n",
        "        \"Article Name\":\"\"\n",
        "    }}\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-4o\",  # Correct model name\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a helpful assistant that extracts structured information from research articles.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            temperature=0.3,\n",
        "            max_tokens=10000,\n",
        "        )\n",
        "        result = response['choices'][0]['message']['content']\n",
        "\n",
        "        # Debug: Print the raw output of the GPT\n",
        "        print(\"GPT Original Output:\", result)\n",
        "\n",
        "        # Extract JSON parts using regular expressions\n",
        "        json_pattern = re.compile(r'\\{.*\\}', re.DOTALL)\n",
        "        match = json_pattern.search(result)\n",
        "        if match:\n",
        "            json_str = match.group()\n",
        "            try:\n",
        "                data = json.loads(json_str)\n",
        "                return data\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(\"JSON decoding error. Please check the extracted JSON string.\")\n",
        "                print(\"Extracted JSON string:\", json_str)\n",
        "                return None\n",
        "        else:\n",
        "            print(\"No JSON content found in GPT's response.\")\n",
        "            return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error calling OpenAI API: {e}\")\n",
        "        return None\n",
        "\n",
        "def process_pdfs(pdf_folder_path, max_pdfs=2):\n",
        "    \"\"\"\n",
        "    Process PDF files in a specified directory to extract summaries.\n",
        "\n",
        "    Args:\n",
        "        pdf_folder_path (str): Path to the directory containing PDF files.\n",
        "        max_pdfs (int): Maximum number of PDF files to process.\n",
        "\n",
        "    Returns:\n",
        "        list: List of dictionaries containing filenames and their corresponding summaries.\n",
        "    \"\"\"\n",
        "    all_summaries = []\n",
        "    count = 0\n",
        "\n",
        "    # Iterate over all files in the specified directory\n",
        "    for filename in os.listdir(pdf_folder_path):\n",
        "        if filename.lower().endswith('.pdf'):\n",
        "            pdf_file_path = os.path.join(pdf_folder_path, filename)\n",
        "            print(f\"Processing {pdf_file_path} ...\")\n",
        "\n",
        "            # Extract text from the PDF\n",
        "            text = extract_text_from_pdf(pdf_file_path)\n",
        "            if not text:\n",
        "                print(f\"Unable to process {pdf_file_path} due to extraction issues.\\n\")\n",
        "                continue\n",
        "\n",
        "            # Extract structured information using OpenAI\n",
        "            info = extract_information(text)\n",
        "            if info:\n",
        "                # Add the extracted information to the summaries list\n",
        "                all_summaries.append({\n",
        "                    \"filename\": filename,\n",
        "                    \"summary\": info\n",
        "                })\n",
        "\n",
        "                # Print the extracted information\n",
        "                print(\"Extracted Information:\")\n",
        "                print(json.dumps(info, ensure_ascii=False, indent=4))\n",
        "                print(\"Summary added to the summaries list.\\n\")\n",
        "            else:\n",
        "                print(\"Failed to extract valid information.\\n\")\n",
        "\n",
        "            count += 1\n",
        "            if count >= max_pdfs:\n",
        "                print(f\"Reached the maximum number of PDFs to process: {max_pdfs}. Stopping processing.\")\n",
        "                break\n",
        "\n",
        "    return all_summaries\n",
        "\n",
        "def save_summaries_to_json(summaries, output_directory='/content', output_filename=\"summaries.json\"):\n",
        "    \"\"\"\n",
        "    Save all summaries to a JSON file.\n",
        "\n",
        "    Args:\n",
        "        summaries (list): List of dictionaries containing summaries.\n",
        "        output_directory (str): Directory where the JSON file will be saved.\n",
        "        output_filename (str): Name of the output JSON file.\n",
        "    \"\"\"\n",
        "    output_file_path = os.path.join(output_directory, output_filename)\n",
        "    try:\n",
        "        with open(output_file_path, 'w', encoding='utf-8') as json_file:\n",
        "            json.dump(summaries, json_file, ensure_ascii=False, indent=4)\n",
        "        print(f\"All summaries have been saved to {output_file_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving summaries to file: {e}\")\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to execute the PDF processing and summary extraction.\n",
        "    \"\"\"\n",
        "    # Define the path to the folder containing PDF files\n",
        "    pdf_folder_path = '/content/papers/32 article'  # Replace with your actual PDF folder path\n",
        "\n",
        "    # Define the maximum number of PDFs to process\n",
        "    max_pdfs = 32  # Set the number of PDFs you want to process\n",
        "\n",
        "    # Process the PDFs and extract summaries\n",
        "    all_summaries = process_pdfs(pdf_folder_path, max_pdfs=max_pdfs)\n",
        "\n",
        "    # Save the summaries to a JSON file\n",
        "    save_summaries_to_json(all_summaries, output_directory='/content', output_filename=\"summaries.json\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "OufJLb1dlWnR",
        "outputId": "658efcc2-eafa-44a5-8ab8-5869d54d4112"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing /content/papers/32 article/retrieve-3.pdf ...\n",
            "GPT Original Output: {\n",
            "    \"Context\": \"The study is focused on the call center customer service industry.\",\n",
            "    \"Research Question and Findings\": \"The main research question is how the introduction of voice-based AI systems impacts call length, customers' demand for human service, and customer complaints in call center customer services. The key findings are that the AI system temporarily increases call length and demand for human service but persistently reduces customer complaints. The AI system is more effective for simple requests and for older, female, and experienced customers.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"The AI system reduces customer complaints more effectively than the traditional IVR system, especially for simple service requests. However, speech-recognition failures can lead to increased demand for human service and complaints.\",\n",
            "        \"Human + AI Collaboration\": \"The study discusses the role of AI in handling customer service tasks and the option for customers to transfer to human agents when needed, highlighting a collaborative model where AI handles initial interactions and humans manage complex issues.\"\n",
            "    },\n",
            "    \"Method\": \"Empirical Research (natural field experiment)\",\n",
            "    \"Contribution\": \"The contribution is managerial, providing insights into the implementation and effectiveness of AI systems in call center operations.\",\n",
            "    \"Future Potential and Limitations\": \"Future research could explore other outcome variables such as service satisfaction and customer retention. Limitations include the lack of individual randomization and detailed records of specific service requests.\",\n",
            "    \"Keywords\": \"artificial intelligence, customer service, difference-in-differences, natural field experiment, service flexibility\",\n",
            "    \"Authors\": \"Lingli Wang, Ni Huang, Yili Hong, Luning Liu, Xunhua Guo, Guoqing Chen\",\n",
            "    \"Publication Information\": \"Production and Operations Management, 2023, pages 1002-1018\",\n",
            "    \"Article Name\": \"Voice-based AI in call center customer service: A natural field experiment\"\n",
            "}\n",
            "Extracted Information:\n",
            "{\n",
            "    \"Context\": \"The study is focused on the call center customer service industry.\",\n",
            "    \"Research Question and Findings\": \"The main research question is how the introduction of voice-based AI systems impacts call length, customers' demand for human service, and customer complaints in call center customer services. The key findings are that the AI system temporarily increases call length and demand for human service but persistently reduces customer complaints. The AI system is more effective for simple requests and for older, female, and experienced customers.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"The AI system reduces customer complaints more effectively than the traditional IVR system, especially for simple service requests. However, speech-recognition failures can lead to increased demand for human service and complaints.\",\n",
            "        \"Human + AI Collaboration\": \"The study discusses the role of AI in handling customer service tasks and the option for customers to transfer to human agents when needed, highlighting a collaborative model where AI handles initial interactions and humans manage complex issues.\"\n",
            "    },\n",
            "    \"Method\": \"Empirical Research (natural field experiment)\",\n",
            "    \"Contribution\": \"The contribution is managerial, providing insights into the implementation and effectiveness of AI systems in call center operations.\",\n",
            "    \"Future Potential and Limitations\": \"Future research could explore other outcome variables such as service satisfaction and customer retention. Limitations include the lack of individual randomization and detailed records of specific service requests.\",\n",
            "    \"Keywords\": \"artificial intelligence, customer service, difference-in-differences, natural field experiment, service flexibility\",\n",
            "    \"Authors\": \"Lingli Wang, Ni Huang, Yili Hong, Luning Liu, Xunhua Guo, Guoqing Chen\",\n",
            "    \"Publication Information\": \"Production and Operations Management, 2023, pages 1002-1018\",\n",
            "    \"Article Name\": \"Voice-based AI in call center customer service: A natural field experiment\"\n",
            "}\n",
            "Summary added to the summaries list.\n",
            "\n",
            "Processing /content/papers/32 article/fügener-et-al-2021-cognitive-challenges-in-human-artificial-intelligence-collaboration-investigating-the-path-toward.pdf ...\n",
            "GPT Original Output: {\n",
            "    \"Context\": \"The study focuses on the collaboration between humans and AI in classification tasks.\",\n",
            "    \"Research Question and Findings\": \"The main research questions are whether delegation between humans and AI can outperform humans or AI working alone, and what factors limit human delegation performance. The key findings are that AI delegating to humans (inversion) outperforms both humans and AI working alone, while humans do not delegate well to AI due to a lack of metaknowledge.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"AI outperforms humans when working alone, but humans and AI together can outperform AI alone when AI delegates tasks to humans.\",\n",
            "        \"Human + AI Collaboration\": \"The study discusses the roles of humans and AI in a collaborative setting, highlighting that AI should delegate tasks to humans when uncertain, but humans struggle to delegate effectively to AI due to metaknowledge limitations.\"\n",
            "    },\n",
            "    \"Method\": \"Empirical Research (laboratory experiments)\",\n",
            "    \"Contribution\": \"Theoretical and managerial contributions by highlighting the importance of metaknowledge in human-AI collaboration and providing insights into designing effective human-AI collaborative environments.\",\n",
            "    \"Future Potential and Limitations\": \"Future research should focus on improving human metaknowledge and exploring human-AI collaboration in specialized environments. Limitations include the use of a generic task and non-specialized workers, which may affect generalizability.\",\n",
            "    \"Keywords\": \"future of work, artificial intelligence, machine learning, delegation, metaknowledge, human-AI collaboration\",\n",
            "    \"Authors\": \"Andreas Fügener, Jörn Grahl, Alok Gupta, Wolfgang Ketter\",\n",
            "    \"Publication Information\": \"Information Systems Research, Vol. 33, No. 2, June 2022, pp. 678-696, © 2021 The Author(s)\",\n",
            "    \"Article Name\": \"Cognitive Challenges in Human–Artificial Intelligence Collaboration: Investigating the Path Toward Productive Delegation\"\n",
            "}\n",
            "Extracted Information:\n",
            "{\n",
            "    \"Context\": \"The study focuses on the collaboration between humans and AI in classification tasks.\",\n",
            "    \"Research Question and Findings\": \"The main research questions are whether delegation between humans and AI can outperform humans or AI working alone, and what factors limit human delegation performance. The key findings are that AI delegating to humans (inversion) outperforms both humans and AI working alone, while humans do not delegate well to AI due to a lack of metaknowledge.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"AI outperforms humans when working alone, but humans and AI together can outperform AI alone when AI delegates tasks to humans.\",\n",
            "        \"Human + AI Collaboration\": \"The study discusses the roles of humans and AI in a collaborative setting, highlighting that AI should delegate tasks to humans when uncertain, but humans struggle to delegate effectively to AI due to metaknowledge limitations.\"\n",
            "    },\n",
            "    \"Method\": \"Empirical Research (laboratory experiments)\",\n",
            "    \"Contribution\": \"Theoretical and managerial contributions by highlighting the importance of metaknowledge in human-AI collaboration and providing insights into designing effective human-AI collaborative environments.\",\n",
            "    \"Future Potential and Limitations\": \"Future research should focus on improving human metaknowledge and exploring human-AI collaboration in specialized environments. Limitations include the use of a generic task and non-specialized workers, which may affect generalizability.\",\n",
            "    \"Keywords\": \"future of work, artificial intelligence, machine learning, delegation, metaknowledge, human-AI collaboration\",\n",
            "    \"Authors\": \"Andreas Fügener, Jörn Grahl, Alok Gupta, Wolfgang Ketter\",\n",
            "    \"Publication Information\": \"Information Systems Research, Vol. 33, No. 2, June 2022, pp. 678-696, © 2021 The Author(s)\",\n",
            "    \"Article Name\": \"Cognitive Challenges in Human–Artificial Intelligence Collaboration: Investigating the Path Toward Productive Delegation\"\n",
            "}\n",
            "Summary added to the summaries list.\n",
            "\n",
            "Processing /content/papers/32 article/retrieve.pdf ...\n",
            "GPT Original Output: {\n",
            "    \"Context\": \"The study is focused on the sales industry, specifically on the use of AI coaches for training sales agents.\",\n",
            "    \"Research Question and Findings\": \"The main research questions are: (1) Which types of sales agents benefit the most and the least from AI versus human coaches? (2) What is the underlying mechanism? (3) Can an assemblage of AI and human coach qualities improve sales performance? Key findings include that AI coaches have an inverted-U impact on agent performance, benefiting middle-ranked agents the most. Bottom-ranked agents face information overload, while top-ranked agents have aversion to AI coaches. An AI-human coach assemblage outperforms either coach alone.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"AI coaches have superior data computation skills but lack interpersonal communication skills compared to human managers. Middle-ranked agents benefit the most from AI coaches, while bottom-ranked agents face information overload and top-ranked agents have aversion to AI.\",\n",
            "        \"Human + AI Collaboration\": \"The study discusses an AI-human coach assemblage where AI provides data-driven feedback and human managers communicate it, leveraging AI's data skills and human's interpersonal skills.\"\n",
            "    },\n",
            "    \"Method\": \"Empirical Research (randomized field experiments)\",\n",
            "    \"Contribution\": \"Managerial contribution by providing insights into effectively leveraging AI coaches in sales training and highlighting the benefits of AI-human collaboration.\",\n",
            "    \"Future Potential and Limitations\": \"Future research could explore the generalizability of findings to other industries and long-term effects. Limitations include the focus on short-term effects and specific sales tasks.\",\n",
            "    \"Keywords\": \"AI coach, artificial intelligence, aversion, information overload, sales training, sales force management\",\n",
            "    \"Authors\": \"Xueming Luo, Marco Shaojun Qin, Zheng Fang, Zhe Qu\",\n",
            "    \"Publication Information\": \"Journal of Marketing, Vol. 85(2), pages 14-32, 2021\",\n",
            "    \"Article Name\": \"Artificial Intelligence Coaches for Sales Agents: Caveats and Solutions\"\n",
            "}\n",
            "Extracted Information:\n",
            "{\n",
            "    \"Context\": \"The study is focused on the sales industry, specifically on the use of AI coaches for training sales agents.\",\n",
            "    \"Research Question and Findings\": \"The main research questions are: (1) Which types of sales agents benefit the most and the least from AI versus human coaches? (2) What is the underlying mechanism? (3) Can an assemblage of AI and human coach qualities improve sales performance? Key findings include that AI coaches have an inverted-U impact on agent performance, benefiting middle-ranked agents the most. Bottom-ranked agents face information overload, while top-ranked agents have aversion to AI coaches. An AI-human coach assemblage outperforms either coach alone.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"AI coaches have superior data computation skills but lack interpersonal communication skills compared to human managers. Middle-ranked agents benefit the most from AI coaches, while bottom-ranked agents face information overload and top-ranked agents have aversion to AI.\",\n",
            "        \"Human + AI Collaboration\": \"The study discusses an AI-human coach assemblage where AI provides data-driven feedback and human managers communicate it, leveraging AI's data skills and human's interpersonal skills.\"\n",
            "    },\n",
            "    \"Method\": \"Empirical Research (randomized field experiments)\",\n",
            "    \"Contribution\": \"Managerial contribution by providing insights into effectively leveraging AI coaches in sales training and highlighting the benefits of AI-human collaboration.\",\n",
            "    \"Future Potential and Limitations\": \"Future research could explore the generalizability of findings to other industries and long-term effects. Limitations include the focus on short-term effects and specific sales tasks.\",\n",
            "    \"Keywords\": \"AI coach, artificial intelligence, aversion, information overload, sales training, sales force management\",\n",
            "    \"Authors\": \"Xueming Luo, Marco Shaojun Qin, Zheng Fang, Zhe Qu\",\n",
            "    \"Publication Information\": \"Journal of Marketing, Vol. 85(2), pages 14-32, 2021\",\n",
            "    \"Article Name\": \"Artificial Intelligence Coaches for Sales Agents: Caveats and Solutions\"\n",
            "}\n",
            "Summary added to the summaries list.\n",
            "\n",
            "Processing /content/papers/32 article/mnsc.2021.4190.pdf ...\n",
            "GPT Original Output: {\n",
            "    \"Context\": \"The study is focused on the semiconductor manufacturing industry.\",\n",
            "    \"Research Question and Findings\": \"The main research question is how explainable artificial intelligence can be used to improve process quality in manufacturing. The key findings are that using a data-driven decision model with explainable AI can significantly reduce yield loss, as demonstrated by a 21.7% reduction in yield loss in a field experiment.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"The study highlights the operational value of explainable AI in identifying critical drivers of process quality that traditional methods may miss.\",\n",
            "        \"Human + AI Collaboration\": \"The research discusses collaboration where AI provides insights through SHAP values, and human experts use these insights to identify potential causal pathways and implement improvement actions.\"\n",
            "    },\n",
            "    \"Method\": \"Empirical Research (field experiments and secondary data analysis)\",\n",
            "    \"Contribution\": \"Managerial\",\n",
            "    \"Future Potential and Limitations\": \"The study suggests that the decision model can be generalized to other manufacturing settings with high data coverage. However, it is limited by its reliance on correlations and past observations, which may not capture unobserved quality drivers.\",\n",
            "    \"Keywords\": \"manufacturing, quality management, artificial intelligence, SHAP value method\",\n",
            "    \"Authors\": \"Julian Senoner, Torbjørn Netland, Stefan Feuerriegel\",\n",
            "    \"Publication Information\": \"Management Science, Vol. 68, No. 8, August 2022, pp. 5704-5723\",\n",
            "    \"Article Name\": \"Using Explainable Artificial Intelligence to Improve Process Quality: Evidence from Semiconductor Manufacturing\"\n",
            "}\n",
            "Extracted Information:\n",
            "{\n",
            "    \"Context\": \"The study is focused on the semiconductor manufacturing industry.\",\n",
            "    \"Research Question and Findings\": \"The main research question is how explainable artificial intelligence can be used to improve process quality in manufacturing. The key findings are that using a data-driven decision model with explainable AI can significantly reduce yield loss, as demonstrated by a 21.7% reduction in yield loss in a field experiment.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"The study highlights the operational value of explainable AI in identifying critical drivers of process quality that traditional methods may miss.\",\n",
            "        \"Human + AI Collaboration\": \"The research discusses collaboration where AI provides insights through SHAP values, and human experts use these insights to identify potential causal pathways and implement improvement actions.\"\n",
            "    },\n",
            "    \"Method\": \"Empirical Research (field experiments and secondary data analysis)\",\n",
            "    \"Contribution\": \"Managerial\",\n",
            "    \"Future Potential and Limitations\": \"The study suggests that the decision model can be generalized to other manufacturing settings with high data coverage. However, it is limited by its reliance on correlations and past observations, which may not capture unobserved quality drivers.\",\n",
            "    \"Keywords\": \"manufacturing, quality management, artificial intelligence, SHAP value method\",\n",
            "    \"Authors\": \"Julian Senoner, Torbjørn Netland, Stefan Feuerriegel\",\n",
            "    \"Publication Information\": \"Management Science, Vol. 68, No. 8, August 2022, pp. 5704-5723\",\n",
            "    \"Article Name\": \"Using Explainable Artificial Intelligence to Improve Process Quality: Evidence from Semiconductor Manufacturing\"\n",
            "}\n",
            "Summary added to the summaries list.\n",
            "\n",
            "Processing /content/papers/32 article/1911.01391v2.pdf ...\n",
            "GPT Original Output: {\n",
            "    \"Context\": \"The study is focused on the financial industry, specifically on automated investment management through robo-advisors.\",\n",
            "    \"Research Question and Findings\": \"The main research question is how a robo-advisor can optimally personalize investment strategies for clients by interacting with them to understand their risk profiles. The key findings include the development of a framework for adaptive mean-variance portfolio optimization that accounts for client risk profiles and market conditions. The study finds that optimal investment strategies can improve portfolio performance by countering client tendencies to reduce market exposure during economic contractions.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"The study highlights the advantage of AI in processing large amounts of data to personalize investment strategies, potentially outperforming human advisors in mitigating behavioral biases.\",\n",
            "        \"Human + AI Collaboration\": \"The study discusses the collaboration between humans and AI in the form of robo-advisors interacting with clients to gather information about their risk profiles, which is then used to personalize investment strategies.\"\n",
            "    },\n",
            "    \"Method\": \"Modeling (including stylized or Operations Research (OR) models)\",\n",
            "    \"Contribution\": \"Theoretical and managerial contributions by providing a framework for personalized robo-advising and insights into optimal interaction frequencies to balance information acquisition and behavioral bias mitigation.\",\n",
            "    \"Future Potential and Limitations\": \"The study suggests future research directions including the incorporation of multiple tradable assets, threshold-based portfolio rebalancing, and handling hidden economic states. Limitations include assumptions about market return independence from economic state transitions.\",\n",
            "    \"Keywords\": \"Robo-advisors, personalized investment, mean-variance optimization, risk aversion, behavioral biases\",\n",
            "    \"Authors\": \"Agostino Capponi, Sveinn Olafsson, Thaleia Zariphopoulou\",\n",
            "    \"Publication Information\": \"arXiv:1911.01391v2 [q-fin.PM], 24 Nov 2020\",\n",
            "    \"Article Name\": \"Personalized Robo-Advising: Enhancing Investment through Client Interaction\"\n",
            "}\n",
            "Extracted Information:\n",
            "{\n",
            "    \"Context\": \"The study is focused on the financial industry, specifically on automated investment management through robo-advisors.\",\n",
            "    \"Research Question and Findings\": \"The main research question is how a robo-advisor can optimally personalize investment strategies for clients by interacting with them to understand their risk profiles. The key findings include the development of a framework for adaptive mean-variance portfolio optimization that accounts for client risk profiles and market conditions. The study finds that optimal investment strategies can improve portfolio performance by countering client tendencies to reduce market exposure during economic contractions.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"The study highlights the advantage of AI in processing large amounts of data to personalize investment strategies, potentially outperforming human advisors in mitigating behavioral biases.\",\n",
            "        \"Human + AI Collaboration\": \"The study discusses the collaboration between humans and AI in the form of robo-advisors interacting with clients to gather information about their risk profiles, which is then used to personalize investment strategies.\"\n",
            "    },\n",
            "    \"Method\": \"Modeling (including stylized or Operations Research (OR) models)\",\n",
            "    \"Contribution\": \"Theoretical and managerial contributions by providing a framework for personalized robo-advising and insights into optimal interaction frequencies to balance information acquisition and behavioral bias mitigation.\",\n",
            "    \"Future Potential and Limitations\": \"The study suggests future research directions including the incorporation of multiple tradable assets, threshold-based portfolio rebalancing, and handling hidden economic states. Limitations include assumptions about market return independence from economic state transitions.\",\n",
            "    \"Keywords\": \"Robo-advisors, personalized investment, mean-variance optimization, risk aversion, behavioral biases\",\n",
            "    \"Authors\": \"Agostino Capponi, Sveinn Olafsson, Thaleia Zariphopoulou\",\n",
            "    \"Publication Information\": \"arXiv:1911.01391v2 [q-fin.PM], 24 Nov 2020\",\n",
            "    \"Article Name\": \"Personalized Robo-Advising: Enhancing Investment through Client Interaction\"\n",
            "}\n",
            "Summary added to the summaries list.\n",
            "\n",
            "Processing /content/papers/32 article/retrieve-4.pdf ...\n",
            "GPT Original Output: {\n",
            "    \"Context\": \"The study is focused on consumer reactions to decisions made by algorithms versus humans in consumer-facing tasks, such as application evaluations.\",\n",
            "    \"Research Question and Findings\": \"The main research question is how consumers react to favorable versus unfavorable decisions made by algorithms versus humans. The key findings are that consumers react less positively to favorable decisions made by algorithms compared to humans, but this difference is mitigated for unfavorable decisions.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"Humans have an advantage over AI in making favorable decisions as consumers find it easier to internalize favorable outcomes from humans. However, for unfavorable decisions, consumers are indifferent to whether the decision is made by a human or an AI.\",\n",
            "        \"Human + AI Collaboration\": \"The study discusses the potential for human monitoring of AI decisions but finds that mere observation by humans does not improve consumer reactions compared to decisions made solely by algorithms.\"\n",
            "    },\n",
            "    \"Method\": \"Empirical Research (laboratory/field experiments)\",\n",
            "    \"Contribution\": \"Theoretical and managerial contributions by addressing consumer reactions to algorithmic versus human decisions and offering insights into improving consumer responses to algorithmic decisions.\",\n",
            "    \"Future Potential and Limitations\": \"Future research could explore consumer perceptions of human-AI collaboration, the impact of decision criteria, demographic differences, and the communication of decision outcomes. Limitations include the focus on consumer attitudes rather than other behavioral measures.\",\n",
            "    \"Keywords\": \"algorithms, decision making, decision outcome favorability, attribution theory\",\n",
            "    \"Authors\": \"Gizem Yalcin, Sarah Lim, Stefano Puntoni, Stijn M.J. van Osselaer\",\n",
            "    \"Publication Information\": \"Journal of Marketing Research, 2022, Vol. 59(4), pages 696-717\",\n",
            "    \"Article Name\": \"Thumbs Up or Down: Consumer Reactions to Decisions by Algorithms Versus Humans\"\n",
            "}\n",
            "Extracted Information:\n",
            "{\n",
            "    \"Context\": \"The study is focused on consumer reactions to decisions made by algorithms versus humans in consumer-facing tasks, such as application evaluations.\",\n",
            "    \"Research Question and Findings\": \"The main research question is how consumers react to favorable versus unfavorable decisions made by algorithms versus humans. The key findings are that consumers react less positively to favorable decisions made by algorithms compared to humans, but this difference is mitigated for unfavorable decisions.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"Humans have an advantage over AI in making favorable decisions as consumers find it easier to internalize favorable outcomes from humans. However, for unfavorable decisions, consumers are indifferent to whether the decision is made by a human or an AI.\",\n",
            "        \"Human + AI Collaboration\": \"The study discusses the potential for human monitoring of AI decisions but finds that mere observation by humans does not improve consumer reactions compared to decisions made solely by algorithms.\"\n",
            "    },\n",
            "    \"Method\": \"Empirical Research (laboratory/field experiments)\",\n",
            "    \"Contribution\": \"Theoretical and managerial contributions by addressing consumer reactions to algorithmic versus human decisions and offering insights into improving consumer responses to algorithmic decisions.\",\n",
            "    \"Future Potential and Limitations\": \"Future research could explore consumer perceptions of human-AI collaboration, the impact of decision criteria, demographic differences, and the communication of decision outcomes. Limitations include the focus on consumer attitudes rather than other behavioral measures.\",\n",
            "    \"Keywords\": \"algorithms, decision making, decision outcome favorability, attribution theory\",\n",
            "    \"Authors\": \"Gizem Yalcin, Sarah Lim, Stefano Puntoni, Stijn M.J. van Osselaer\",\n",
            "    \"Publication Information\": \"Journal of Marketing Research, 2022, Vol. 59(4), pages 696-717\",\n",
            "    \"Article Name\": \"Thumbs Up or Down: Consumer Reactions to Decisions by Algorithms Versus Humans\"\n",
            "}\n",
            "Summary added to the summaries list.\n",
            "\n",
            "Processing /content/papers/32 article/lu-zhang-2024-1-1-2-information-humans-and-machines.pdf ...\n",
            "GPT Original Output: {\n",
            "    \"Context\": \"The study is focused on the microloan industry, specifically examining human-machine collaboration in decision-making processes.\",\n",
            "    \"Research Question and Findings\": \"The main research questions are: (1) What is the realized performance when humans and machines collaborate under different levels of information complexity and different system designs? (2) What are the underlying mechanisms? (3) How do human characteristics affect collaborative performance? The key findings indicate that human evaluators add value to the decision-making process when large information volumes are coupled with machine explanations, reducing the default rate compared to machine-only decisions.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"Machines generally outperform humans in decision-making accuracy, especially with large information volumes. However, humans can identify rare cases and provide flexibility.\",\n",
            "        \"Human + AI Collaboration\": \"The study discusses a two-stage collaboration process where humans initially make decisions independently and then adjust based on machine recommendations and explanations. Human involvement is valuable when large information volumes and machine explanations are present.\"\n",
            "    },\n",
            "    \"Method\": \"Empirical Research (field experiments)\",\n",
            "    \"Contribution\": \"Theoretical and managerial contributions by revealing the conditions under which human-machine collaboration is effective and providing insights into system designs.\",\n",
            "    \"Future Potential and Limitations\": \"Future research should explore long-term human learning behavior and continuous levels of information complexity. The study's short experimental period and focus on a specific industry may limit generalizability.\",\n",
            "    \"Keywords\": \"decision making, gender biases, human–machine collaboration, information processing, machine explanations, microfinance, rethinking\",\n",
            "    \"Authors\": \"Tian Lu, Yingjie Zhang\",\n",
            "    \"Publication Information\": \"Information Systems Research, Articles in Advance, pp. 1–25, © 2024 INFORMS\",\n",
            "    \"Article Name\": \"Information, Humans, and Machines\"\n",
            "}\n",
            "Extracted Information:\n",
            "{\n",
            "    \"Context\": \"The study is focused on the microloan industry, specifically examining human-machine collaboration in decision-making processes.\",\n",
            "    \"Research Question and Findings\": \"The main research questions are: (1) What is the realized performance when humans and machines collaborate under different levels of information complexity and different system designs? (2) What are the underlying mechanisms? (3) How do human characteristics affect collaborative performance? The key findings indicate that human evaluators add value to the decision-making process when large information volumes are coupled with machine explanations, reducing the default rate compared to machine-only decisions.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"Machines generally outperform humans in decision-making accuracy, especially with large information volumes. However, humans can identify rare cases and provide flexibility.\",\n",
            "        \"Human + AI Collaboration\": \"The study discusses a two-stage collaboration process where humans initially make decisions independently and then adjust based on machine recommendations and explanations. Human involvement is valuable when large information volumes and machine explanations are present.\"\n",
            "    },\n",
            "    \"Method\": \"Empirical Research (field experiments)\",\n",
            "    \"Contribution\": \"Theoretical and managerial contributions by revealing the conditions under which human-machine collaboration is effective and providing insights into system designs.\",\n",
            "    \"Future Potential and Limitations\": \"Future research should explore long-term human learning behavior and continuous levels of information complexity. The study's short experimental period and focus on a specific industry may limit generalizability.\",\n",
            "    \"Keywords\": \"decision making, gender biases, human–machine collaboration, information processing, machine explanations, microfinance, rethinking\",\n",
            "    \"Authors\": \"Tian Lu, Yingjie Zhang\",\n",
            "    \"Publication Information\": \"Information Systems Research, Articles in Advance, pp. 1–25, © 2024 INFORMS\",\n",
            "    \"Article Name\": \"Information, Humans, and Machines\"\n",
            "}\n",
            "Summary added to the summaries list.\n",
            "\n",
            "Processing /content/papers/32 article/te-eni-et-al-2023-reciprocal-human-machine-learning-a-theory-and-an-instantiation-for-the-case-of-message-classification.pdf ...\n",
            "GPT Original Output: {\n",
            "    \"Context\": \"The study is focused on the task of message classification within the cybersecurity industry, specifically in the context of Darknet forums.\",\n",
            "    \"Research Question and Findings\": \"The main research question is how to effectively facilitate joint and continual learning in both humans and machines for text message classification. The key findings include the development of a reciprocal human-machine learning (RHML) configuration that supports learning cycles between humans and machines, improving both human and machine learning processes.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"The study highlights the comparative advantages of humans in providing context and understanding nuanced meanings, while AI excels in processing large volumes of data efficiently.\",\n",
            "        \"Human + AI Collaboration\": \"The research discusses a collaborative approach where humans provide context and feedback to AI systems, and AI systems offer insights and feedback to humans, facilitating mutual learning.\"\n",
            "    },\n",
            "    \"Method\": \"Design Science Research, involving conceptual development, case studies, and experiments.\",\n",
            "    \"Contribution\": \"The main contribution is theoretical, providing a framework for reciprocal learning between humans and AI, along with a practical instantiation in the form of the Fusion system.\",\n",
            "    \"Future Potential and Limitations\": \"Future research could explore the application of RHML in other domains beyond cybersecurity and address challenges related to expert bias and the need for knowledgeable experts. Limitations include the reliance on expert judgment and the specific context of Darknet forums.\",\n",
            "    \"Keywords\": \"design science, human-machine interaction, reciprocal learning\",\n",
            "    \"Authors\": \"Dov Te’eni, Inbal Yahav, Alexely Zagalsky, David Schwartz, Gahl Silverman, Daniel Cohen, Yossi Mann, Dafna Lewinsky\",\n",
            "    \"Publication Information\": \"Management Science, Articles in Advance, pp. 1–26, ISSN 0025-1909 (print), ISSN 1526-5501 (online), Published Online: November 14, 2023\",\n",
            "    \"Article Name\": \"Reciprocal Human-Machine Learning: A Theory and an Instantiation for the Case of Message Classification\"\n",
            "}\n",
            "Extracted Information:\n",
            "{\n",
            "    \"Context\": \"The study is focused on the task of message classification within the cybersecurity industry, specifically in the context of Darknet forums.\",\n",
            "    \"Research Question and Findings\": \"The main research question is how to effectively facilitate joint and continual learning in both humans and machines for text message classification. The key findings include the development of a reciprocal human-machine learning (RHML) configuration that supports learning cycles between humans and machines, improving both human and machine learning processes.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"The study highlights the comparative advantages of humans in providing context and understanding nuanced meanings, while AI excels in processing large volumes of data efficiently.\",\n",
            "        \"Human + AI Collaboration\": \"The research discusses a collaborative approach where humans provide context and feedback to AI systems, and AI systems offer insights and feedback to humans, facilitating mutual learning.\"\n",
            "    },\n",
            "    \"Method\": \"Design Science Research, involving conceptual development, case studies, and experiments.\",\n",
            "    \"Contribution\": \"The main contribution is theoretical, providing a framework for reciprocal learning between humans and AI, along with a practical instantiation in the form of the Fusion system.\",\n",
            "    \"Future Potential and Limitations\": \"Future research could explore the application of RHML in other domains beyond cybersecurity and address challenges related to expert bias and the need for knowledgeable experts. Limitations include the reliance on expert judgment and the specific context of Darknet forums.\",\n",
            "    \"Keywords\": \"design science, human-machine interaction, reciprocal learning\",\n",
            "    \"Authors\": \"Dov Te’eni, Inbal Yahav, Alexely Zagalsky, David Schwartz, Gahl Silverman, Daniel Cohen, Yossi Mann, Dafna Lewinsky\",\n",
            "    \"Publication Information\": \"Management Science, Articles in Advance, pp. 1–26, ISSN 0025-1909 (print), ISSN 1526-5501 (online), Published Online: November 14, 2023\",\n",
            "    \"Article Name\": \"Reciprocal Human-Machine Learning: A Theory and an Instantiation for the Case of Message Classification\"\n",
            "}\n",
            "Summary added to the summaries list.\n",
            "\n",
            "Processing /content/papers/32 article/2008.09283v1.pdf ...\n",
            "GPT Original Output: {\n",
            "    \"Context\": \"The study focuses on the impact of algorithmic transparency in decision-making processes, particularly in the context of firms using machine learning algorithms and strategic users who might manipulate these algorithms.\",\n",
            "    \"Research Question and Findings\": \"The main research question is whether firms should make their algorithms transparent to users, despite the risk of gaming. The key findings suggest that under certain conditions, algorithmic transparency can benefit firms by motivating users to invest in desirable features, even though users might not always benefit from transparency.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"The research explores the strategic interaction between human users and AI algorithms, highlighting that algorithmic transparency can lead to increased user investment in desirable features, potentially improving the predictive power of AI.\",\n",
            "        \"Human + AI Collaboration\": \"The study discusses the sequence of actions where firms decide on transparency and users react by potentially gaming the system, leading to a dynamic interaction between human strategies and AI decision-making.\"\n",
            "    },\n",
            "    \"Method\": \"Modeling (including stylized or Operations Research (OR) models)\",\n",
            "    \"Contribution\": \"Theoretical\",\n",
            "    \"Future Potential and Limitations\": \"Future research could explore the trade-offs between algorithmic transparency, interpretability, and privacy concerns. Limitations include the assumption of cost structures and strategic behavior which may vary in real-world scenarios.\",\n",
            "    \"Keywords\": \"Algorithmic Transparency, Game Theory, Machine Learning, Strategic Classification, Signaling Game\",\n",
            "    \"Authors\": \"Qiaochu Wang, Yan Huang, Stefanus Jasin, Param Vir Singh\",\n",
            "    \"Publication Information\": \"arXiv:2008.09283v1 [cs.GT], 21 Aug 2020\",\n",
            "    \"Article Name\": \"Algorithmic Transparency With Strategic Users\"\n",
            "}\n",
            "Extracted Information:\n",
            "{\n",
            "    \"Context\": \"The study focuses on the impact of algorithmic transparency in decision-making processes, particularly in the context of firms using machine learning algorithms and strategic users who might manipulate these algorithms.\",\n",
            "    \"Research Question and Findings\": \"The main research question is whether firms should make their algorithms transparent to users, despite the risk of gaming. The key findings suggest that under certain conditions, algorithmic transparency can benefit firms by motivating users to invest in desirable features, even though users might not always benefit from transparency.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"The research explores the strategic interaction between human users and AI algorithms, highlighting that algorithmic transparency can lead to increased user investment in desirable features, potentially improving the predictive power of AI.\",\n",
            "        \"Human + AI Collaboration\": \"The study discusses the sequence of actions where firms decide on transparency and users react by potentially gaming the system, leading to a dynamic interaction between human strategies and AI decision-making.\"\n",
            "    },\n",
            "    \"Method\": \"Modeling (including stylized or Operations Research (OR) models)\",\n",
            "    \"Contribution\": \"Theoretical\",\n",
            "    \"Future Potential and Limitations\": \"Future research could explore the trade-offs between algorithmic transparency, interpretability, and privacy concerns. Limitations include the assumption of cost structures and strategic behavior which may vary in real-world scenarios.\",\n",
            "    \"Keywords\": \"Algorithmic Transparency, Game Theory, Machine Learning, Strategic Classification, Signaling Game\",\n",
            "    \"Authors\": \"Qiaochu Wang, Yan Huang, Stefanus Jasin, Param Vir Singh\",\n",
            "    \"Publication Information\": \"arXiv:2008.09283v1 [cs.GT], 21 Aug 2020\",\n",
            "    \"Article Name\": \"Algorithmic Transparency With Strategic Users\"\n",
            "}\n",
            "Summary added to the summaries list.\n",
            "\n",
            "Processing /content/papers/32 article/retrieve-7.pdf ...\n",
            "GPT Original Output: {\n",
            "    \"Context\": \"The study is focused on organizations using artificial intelligence (AI) for hybrid problem-solving, particularly in exploratory tasks.\",\n",
            "    \"Research Question and Findings\": \"The main research question is how combining human intelligence with AI affects problem-solving processes and outcomes in organizations. The key findings are that different hybrid problem-solving processes (autonomous, sequential, interactive) lead to varying outcomes, with autonomous search generating more distant solutions, sequential search enabling more local solutions, and interactive search promoting more recombinative outcomes.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"AI can perform cognitive functions like decision-making and problem-solving without human cognitive limitations, often providing superior predictions.\",\n",
            "        \"Human + AI Collaboration\": \"Three types of collaboration are discussed: autonomous search (AI generates solutions independently), sequential search (AI defines the problem, humans search for solutions), and interactive search (humans and AI search jointly).\"\n",
            "    },\n",
            "    \"Method\": \"Conceptual/Case Study\",\n",
            "    \"Contribution\": \"Theoretical and managerial contributions by enriching the behavioral theory of the firm with a technology-conscious perspective and extending AI management literature to include generative AI applications.\",\n",
            "    \"Future Potential and Limitations\": \"Future research should explore the role of humans in preparing and enabling AI use in situations with limited data, strategic selection of hybrid types, and the societal implications of AI-based search.\",\n",
            "    \"Keywords\": \"Artificial Intelligence, Hybrid Problem-Solving, Organizations, Behavioral Theory, Generative AI, Predictive AI, Human-AI Collaboration\",\n",
            "    \"Authors\": \"Sebastian Raisch, Kateryna Fomina\",\n",
            "    \"Publication Information\": \"Academy of Management Review, 2023, Vol. 00, No. 00, pages 1-24\",\n",
            "    \"Article Name\": \"Combining Human and Artificial Intelligence: Hybrid Problem-Solving in Organizations\"\n",
            "}\n",
            "Extracted Information:\n",
            "{\n",
            "    \"Context\": \"The study is focused on organizations using artificial intelligence (AI) for hybrid problem-solving, particularly in exploratory tasks.\",\n",
            "    \"Research Question and Findings\": \"The main research question is how combining human intelligence with AI affects problem-solving processes and outcomes in organizations. The key findings are that different hybrid problem-solving processes (autonomous, sequential, interactive) lead to varying outcomes, with autonomous search generating more distant solutions, sequential search enabling more local solutions, and interactive search promoting more recombinative outcomes.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"AI can perform cognitive functions like decision-making and problem-solving without human cognitive limitations, often providing superior predictions.\",\n",
            "        \"Human + AI Collaboration\": \"Three types of collaboration are discussed: autonomous search (AI generates solutions independently), sequential search (AI defines the problem, humans search for solutions), and interactive search (humans and AI search jointly).\"\n",
            "    },\n",
            "    \"Method\": \"Conceptual/Case Study\",\n",
            "    \"Contribution\": \"Theoretical and managerial contributions by enriching the behavioral theory of the firm with a technology-conscious perspective and extending AI management literature to include generative AI applications.\",\n",
            "    \"Future Potential and Limitations\": \"Future research should explore the role of humans in preparing and enabling AI use in situations with limited data, strategic selection of hybrid types, and the societal implications of AI-based search.\",\n",
            "    \"Keywords\": \"Artificial Intelligence, Hybrid Problem-Solving, Organizations, Behavioral Theory, Generative AI, Predictive AI, Human-AI Collaboration\",\n",
            "    \"Authors\": \"Sebastian Raisch, Kateryna Fomina\",\n",
            "    \"Publication Information\": \"Academy of Management Review, 2023, Vol. 00, No. 00, pages 1-24\",\n",
            "    \"Article Name\": \"Combining Human and Artificial Intelligence: Hybrid Problem-Solving in Organizations\"\n",
            "}\n",
            "Summary added to the summaries list.\n",
            "\n",
            "Processing /content/papers/32 article/liu-et-al-2023-unintended-consequences-of-advances-in-matching-technologies-information-revelation-and-strategic.pdf ...\n",
            "GPT Original Output: {\n",
            "    \"Context\": \"The study is focused on gig-economy platforms, specifically examining the impact of advanced matching technologies on these platforms.\",\n",
            "    \"Research Question and Findings\": \"The main research question is how advanced matching technologies affect worker participation and platform revenue in the gig economy. The key findings suggest that while better matching technologies can improve matching quality, they may also unintentionally reveal demand information that discourages worker participation, potentially leading to revenue loss for platforms.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"The study highlights that while AI-driven matching technologies can enhance matching quality, they may also reveal information that affects worker participation decisions, potentially leading to negative outcomes for platforms.\",\n",
            "        \"Human + AI Collaboration\": \"The research discusses the role of AI in matching workers with employers and how workers use the information revealed by AI-driven matches to make strategic participation decisions.\"\n",
            "    },\n",
            "    \"Method\": \"Modeling (stylized game-theoretic model)\",\n",
            "    \"Contribution\": \"Theoretical\",\n",
            "    \"Future Potential and Limitations\": \"The study suggests future research could explore the dynamics of platform competition and the strategic behavior of employers. Limitations include not modeling strategic employers and focusing primarily on worker behavior.\",\n",
            "    \"Keywords\": \"matching technologies, gig worker, game theory, platform strategy\",\n",
            "    \"Authors\": \"Yi Liu, Bowen Lou, Xinyi Zhao, Xinxin Li\",\n",
            "    \"Publication Information\": \"Management Science, Vol. 70, No. 3, March 2024, pp. 1729–1754\",\n",
            "    \"Article Name\": \"Unintended Consequences of Advances in Matching Technologies: Information Revelation and Strategic Participation on Gig-Economy Platforms\"\n",
            "}\n",
            "Extracted Information:\n",
            "{\n",
            "    \"Context\": \"The study is focused on gig-economy platforms, specifically examining the impact of advanced matching technologies on these platforms.\",\n",
            "    \"Research Question and Findings\": \"The main research question is how advanced matching technologies affect worker participation and platform revenue in the gig economy. The key findings suggest that while better matching technologies can improve matching quality, they may also unintentionally reveal demand information that discourages worker participation, potentially leading to revenue loss for platforms.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"The study highlights that while AI-driven matching technologies can enhance matching quality, they may also reveal information that affects worker participation decisions, potentially leading to negative outcomes for platforms.\",\n",
            "        \"Human + AI Collaboration\": \"The research discusses the role of AI in matching workers with employers and how workers use the information revealed by AI-driven matches to make strategic participation decisions.\"\n",
            "    },\n",
            "    \"Method\": \"Modeling (stylized game-theoretic model)\",\n",
            "    \"Contribution\": \"Theoretical\",\n",
            "    \"Future Potential and Limitations\": \"The study suggests future research could explore the dynamics of platform competition and the strategic behavior of employers. Limitations include not modeling strategic employers and focusing primarily on worker behavior.\",\n",
            "    \"Keywords\": \"matching technologies, gig worker, game theory, platform strategy\",\n",
            "    \"Authors\": \"Yi Liu, Bowen Lou, Xinyi Zhao, Xinxin Li\",\n",
            "    \"Publication Information\": \"Management Science, Vol. 70, No. 3, March 2024, pp. 1729–1754\",\n",
            "    \"Article Name\": \"Unintended Consequences of Advances in Matching Technologies: Information Revelation and Strategic Participation on Gig-Economy Platforms\"\n",
            "}\n",
            "Summary added to the summaries list.\n",
            "\n",
            "Processing /content/papers/32 article/de-véricourt-gurkan-2023-is-your-machine-better-than-you-you-may-never-know.pdf ...\n",
            "GPT Original Output: {\n",
            "    \"Context\": \"The study focuses on decision-making in high-stakes environments, particularly in fields like medical and judiciary sectors where machine learning algorithms are used to assist human decision-makers.\",\n",
            "    \"Research Question and Findings\": \"The main research question is whether a decision maker can properly assess if a machine produces better recommendations than human expertise. The key findings indicate that decision makers may never fully learn whether a machine is superior due to verification bias and exploration-free decisions, leading to persistent hesitation or random inference.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"The study highlights that AI systems can make better predictions than humans, but human decision-makers sometimes wrongly override AI recommendations due to verification bias.\",\n",
            "        \"Human + AI Collaboration\": \"The research explores scenarios where humans and AI systems complement each other, particularly when decision makers are unsure about the AI's accuracy, leading to a form of collaboration where AI and human judgments are combined.\"\n",
            "    },\n",
            "    \"Method\": \"Modeling (including stylized or Operations Research (OR) models)\",\n",
            "    \"Contribution\": \"Theoretical\",\n",
            "    \"Future Potential and Limitations\": \"The study suggests that future research should explore the interaction of mistrust biases with the decision-making process and consider scenarios where the verification bias is partially relaxed. Limitations include the assumption of only two possible machine types and the exclusion of intrinsic mistrust biases.\",\n",
            "    \"Keywords\": \"machine accuracy, decision making, human in the loop, algorithm aversion, dynamic learning\",\n",
            "    \"Authors\": \"Francis de Véricourt, Huseyin Gurkan\",\n",
            "    \"Publication Information\": \"Management Science, Articles in Advance, pp. 1–17, © 2023 INFORMS\",\n",
            "    \"Article Name\": \"Is Your Machine Better Than You? You May Never Know\"\n",
            "}\n",
            "Extracted Information:\n",
            "{\n",
            "    \"Context\": \"The study focuses on decision-making in high-stakes environments, particularly in fields like medical and judiciary sectors where machine learning algorithms are used to assist human decision-makers.\",\n",
            "    \"Research Question and Findings\": \"The main research question is whether a decision maker can properly assess if a machine produces better recommendations than human expertise. The key findings indicate that decision makers may never fully learn whether a machine is superior due to verification bias and exploration-free decisions, leading to persistent hesitation or random inference.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"The study highlights that AI systems can make better predictions than humans, but human decision-makers sometimes wrongly override AI recommendations due to verification bias.\",\n",
            "        \"Human + AI Collaboration\": \"The research explores scenarios where humans and AI systems complement each other, particularly when decision makers are unsure about the AI's accuracy, leading to a form of collaboration where AI and human judgments are combined.\"\n",
            "    },\n",
            "    \"Method\": \"Modeling (including stylized or Operations Research (OR) models)\",\n",
            "    \"Contribution\": \"Theoretical\",\n",
            "    \"Future Potential and Limitations\": \"The study suggests that future research should explore the interaction of mistrust biases with the decision-making process and consider scenarios where the verification bias is partially relaxed. Limitations include the assumption of only two possible machine types and the exclusion of intrinsic mistrust biases.\",\n",
            "    \"Keywords\": \"machine accuracy, decision making, human in the loop, algorithm aversion, dynamic learning\",\n",
            "    \"Authors\": \"Francis de Véricourt, Huseyin Gurkan\",\n",
            "    \"Publication Information\": \"Management Science, Articles in Advance, pp. 1–17, © 2023 INFORMS\",\n",
            "    \"Article Name\": \"Is Your Machine Better Than You? You May Never Know\"\n",
            "}\n",
            "Summary added to the summaries list.\n",
            "\n",
            "Processing /content/papers/32 article/Strategic Management Journal - 2022 - Krakowski - Artificial intelligence and the changing sources of competitive advantage.pdf ...\n",
            "GPT Original Output: {\n",
            "    \"Context\": \"The study focuses on the chess industry as a controlled setting to investigate competitive interactions involving AI.\",\n",
            "    \"Research Question and Findings\": \"The main research question is how the adoption of AI affects competitive capabilities and performance. The key findings indicate that AI adoption triggers substitution and complementation dynamics, making traditional human competitive capabilities obsolete while creating new sources of competitive advantage through human-machine interaction.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"AI substitutes human cognitive capabilities, making traditional human capabilities obsolete in competitive settings like chess.\",\n",
            "        \"Human + AI Collaboration\": \"The study discusses human-machine collaboration in centaur chess, where humans and AI work together, and engine chess, where humans select, tune, and govern AI engines.\"\n",
            "    },\n",
            "    \"Method\": \"Empirical Research (secondary data analysis of chess tournaments)\",\n",
            "    \"Contribution\": \"Theoretical and managerial contributions by providing an integrated view of substitution and complementation dynamics in AI adoption.\",\n",
            "    \"Future Potential and Limitations\": \"The study suggests future research should explore AI's impact in other domains and consider multilevel settings. Limitations include the focus on a single domain (chess) and the need for further exploration in business contexts.\",\n",
            "    \"Keywords\": \"artificial intelligence, competitive behavior, decision making, firm capabilities, resource-based view\",\n",
            "    \"Authors\": \"Sebastian Krakowski, Johannes Luger, Sebastian Raisch\",\n",
            "    \"Publication Information\": \"Strategic Management Journal, 2023, pages 1425-1452\",\n",
            "    \"Article Name\": \"Artificial intelligence and the changing sources of competitive advantage\"\n",
            "}\n",
            "Extracted Information:\n",
            "{\n",
            "    \"Context\": \"The study focuses on the chess industry as a controlled setting to investigate competitive interactions involving AI.\",\n",
            "    \"Research Question and Findings\": \"The main research question is how the adoption of AI affects competitive capabilities and performance. The key findings indicate that AI adoption triggers substitution and complementation dynamics, making traditional human competitive capabilities obsolete while creating new sources of competitive advantage through human-machine interaction.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"AI substitutes human cognitive capabilities, making traditional human capabilities obsolete in competitive settings like chess.\",\n",
            "        \"Human + AI Collaboration\": \"The study discusses human-machine collaboration in centaur chess, where humans and AI work together, and engine chess, where humans select, tune, and govern AI engines.\"\n",
            "    },\n",
            "    \"Method\": \"Empirical Research (secondary data analysis of chess tournaments)\",\n",
            "    \"Contribution\": \"Theoretical and managerial contributions by providing an integrated view of substitution and complementation dynamics in AI adoption.\",\n",
            "    \"Future Potential and Limitations\": \"The study suggests future research should explore AI's impact in other domains and consider multilevel settings. Limitations include the focus on a single domain (chess) and the need for further exploration in business contexts.\",\n",
            "    \"Keywords\": \"artificial intelligence, competitive behavior, decision making, firm capabilities, resource-based view\",\n",
            "    \"Authors\": \"Sebastian Krakowski, Johannes Luger, Sebastian Raisch\",\n",
            "    \"Publication Information\": \"Strategic Management Journal, 2023, pages 1425-1452\",\n",
            "    \"Article Name\": \"Artificial intelligence and the changing sources of competitive advantage\"\n",
            "}\n",
            "Summary added to the summaries list.\n",
            "\n",
            "Processing /content/papers/32 article/mele-et-al-2022-how-artificial-intelligence-enhances-human-learning-abilities-opportunities-in-the-fight-against-covid.pdf ...\n",
            "GPT Original Output: {\n",
            "    \"Context\": \"The study focuses on the healthcare industry, specifically on how AI can enhance human learning abilities in the context of COVID-19.\",\n",
            "    \"Research Question and Findings\": \"The main research question is how AI can enhance human learning abilities. The study finds that AI can significantly enhance human learning by assisting in remembering, understanding, analyzing, applying, evaluating, and creating knowledge, particularly in the healthcare context during the COVID-19 pandemic.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"The study highlights that AI can perform tasks such as data extraction, analysis, and emotional recognition more efficiently than humans, particularly in repetitive and data-intensive tasks.\",\n",
            "        \"Human + AI Collaboration\": \"The study discusses collaboration where AI assists humans by enhancing their learning abilities, allowing humans to focus on higher-level cognitive tasks while AI handles data processing and analysis.\"\n",
            "    },\n",
            "    \"Method\": \"Conceptual/Case Study\",\n",
            "    \"Contribution\": \"Theoretical\",\n",
            "    \"Future Potential and Limitations\": \"The study suggests future research could explore the combination of different types of AI and their applications in other fields beyond healthcare. It also notes the need to address challenges and constraints in AI-enabled learning processes.\",\n",
            "    \"Keywords\": \"artificial intelligence, human learning abilities, Bloom's revised taxonomy, COVID-19\",\n",
            "    \"Authors\": \"Cristina Mele, Marialuisa Marzullo, Swapnil Morande, Tiziana Russo Spena\",\n",
            "    \"Publication Information\": \"Service Science, Vol. 14, No. 2, June 2022, pp. 77-89\",\n",
            "    \"Article Name\": \"How Artificial Intelligence Enhances Human Learning Abilities: Opportunities in the Fight Against COVID-19\"\n",
            "}\n",
            "Extracted Information:\n",
            "{\n",
            "    \"Context\": \"The study focuses on the healthcare industry, specifically on how AI can enhance human learning abilities in the context of COVID-19.\",\n",
            "    \"Research Question and Findings\": \"The main research question is how AI can enhance human learning abilities. The study finds that AI can significantly enhance human learning by assisting in remembering, understanding, analyzing, applying, evaluating, and creating knowledge, particularly in the healthcare context during the COVID-19 pandemic.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"The study highlights that AI can perform tasks such as data extraction, analysis, and emotional recognition more efficiently than humans, particularly in repetitive and data-intensive tasks.\",\n",
            "        \"Human + AI Collaboration\": \"The study discusses collaboration where AI assists humans by enhancing their learning abilities, allowing humans to focus on higher-level cognitive tasks while AI handles data processing and analysis.\"\n",
            "    },\n",
            "    \"Method\": \"Conceptual/Case Study\",\n",
            "    \"Contribution\": \"Theoretical\",\n",
            "    \"Future Potential and Limitations\": \"The study suggests future research could explore the combination of different types of AI and their applications in other fields beyond healthcare. It also notes the need to address challenges and constraints in AI-enabled learning processes.\",\n",
            "    \"Keywords\": \"artificial intelligence, human learning abilities, Bloom's revised taxonomy, COVID-19\",\n",
            "    \"Authors\": \"Cristina Mele, Marialuisa Marzullo, Swapnil Morande, Tiziana Russo Spena\",\n",
            "    \"Publication Information\": \"Service Science, Vol. 14, No. 2, June 2022, pp. 77-89\",\n",
            "    \"Article Name\": \"How Artificial Intelligence Enhances Human Learning Abilities: Opportunities in the Fight Against COVID-19\"\n",
            "}\n",
            "Summary added to the summaries list.\n",
            "\n",
            "Processing /content/papers/32 article/feldman-et-al-2021-customer-choice-models-vs-machine-learning-finding-optimal-product-displays-on-alibaba.pdf ...\n",
            "GPT Original Output: {\n",
            "    \"Context\": \"The study is focused on the retail industry, specifically on optimizing product displays on Alibaba's online marketplaces, Tmall and Taobao.\",\n",
            "    \"Research Question and Findings\": \"The main research question is whether a multinomial logit (MNL) model can outperform Alibaba's current machine-learning-based approach in optimizing product displays. The key findings are that the MNL-based approach generated 28% higher revenue per customer visit compared to the machine-learning-based approach using the same set of 25 features, and it is estimated to increase Alibaba's annual revenue by 87.26 million RMB when using the full feature set.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"The study compares the predictive accuracy and revenue performance of human-designed choice models (MNL) versus machine-learning models, finding that while machine-learning models have higher predictive accuracy, the MNL model leads to higher revenue.\",\n",
            "        \"Human + AI Collaboration\": \"The collaboration involves using historical sales data and feature engineering to enhance the MNL model, which is developed and implemented in collaboration with Alibaba engineers.\"\n",
            "    },\n",
            "    \"Method\": \"Empirical Research (field experiments)\",\n",
            "    \"Contribution\": \"Managerial contribution, as it provides insights into the practical implementation of choice models in retail operations and their impact on revenue.\",\n",
            "    \"Future Potential and Limitations\": \"The study suggests future research should focus on developing choice models that can handle click behavior and multiple distinct purchases. It also notes the limitation that results are specific to Alibaba's setting and may not generalize to other contexts.\",\n",
            "    \"Keywords\": \"choice models, product assortment, machine learning, field experiment, retail operations\",\n",
            "    \"Authors\": \"Jacob Feldman, Dennis J. Zhang, Xiaofei Liu, Nannan Zhang\",\n",
            "    \"Publication Information\": \"Operations Research, Vol. 70, No. 1, January–February 2022, pp. 309–328, © 2021 INFORMS\",\n",
            "    \"Article Name\": \"Customer Choice Models vs. Machine Learning: Finding Optimal Product Displays on Alibaba\"\n",
            "}\n",
            "Extracted Information:\n",
            "{\n",
            "    \"Context\": \"The study is focused on the retail industry, specifically on optimizing product displays on Alibaba's online marketplaces, Tmall and Taobao.\",\n",
            "    \"Research Question and Findings\": \"The main research question is whether a multinomial logit (MNL) model can outperform Alibaba's current machine-learning-based approach in optimizing product displays. The key findings are that the MNL-based approach generated 28% higher revenue per customer visit compared to the machine-learning-based approach using the same set of 25 features, and it is estimated to increase Alibaba's annual revenue by 87.26 million RMB when using the full feature set.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"The study compares the predictive accuracy and revenue performance of human-designed choice models (MNL) versus machine-learning models, finding that while machine-learning models have higher predictive accuracy, the MNL model leads to higher revenue.\",\n",
            "        \"Human + AI Collaboration\": \"The collaboration involves using historical sales data and feature engineering to enhance the MNL model, which is developed and implemented in collaboration with Alibaba engineers.\"\n",
            "    },\n",
            "    \"Method\": \"Empirical Research (field experiments)\",\n",
            "    \"Contribution\": \"Managerial contribution, as it provides insights into the practical implementation of choice models in retail operations and their impact on revenue.\",\n",
            "    \"Future Potential and Limitations\": \"The study suggests future research should focus on developing choice models that can handle click behavior and multiple distinct purchases. It also notes the limitation that results are specific to Alibaba's setting and may not generalize to other contexts.\",\n",
            "    \"Keywords\": \"choice models, product assortment, machine learning, field experiment, retail operations\",\n",
            "    \"Authors\": \"Jacob Feldman, Dennis J. Zhang, Xiaofei Liu, Nannan Zhang\",\n",
            "    \"Publication Information\": \"Operations Research, Vol. 70, No. 1, January–February 2022, pp. 309–328, © 2021 INFORMS\",\n",
            "    \"Article Name\": \"Customer Choice Models vs. Machine Learning: Finding Optimal Product Displays on Alibaba\"\n",
            "}\n",
            "Summary added to the summaries list.\n",
            "\n",
            "Processing /content/papers/32 article/wang-et-al-2023-friend-or-foe-teaming-between-artificial-intelligence-and-workers-with-variation-in-experience.pdf ...\n",
            "GPT Original Output: {\n",
            "    \"Context\": \"The study focuses on the healthcare industry, specifically on medical chart coding in a publicly traded company.\",\n",
            "    \"Research Question and Findings\": \"The main research question is how knowledge workers with different levels and types of experience can team with AI for productivity gains. The key findings are that AI benefits workers with greater task-based experience, but senior workers gain less from AI than their junior colleagues due to lower trust in AI.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"AI boosts productivity for all workers but more so for workers with greater task-based experience and less so for workers with greater time-based experience.\",\n",
            "        \"Human + AI Collaboration\": \"The study discusses AI as an augmentation tool for human workers, highlighting sentences with potential HCC codes for review by human coders.\"\n",
            "    },\n",
            "    \"Method\": \"Empirical Research (field experiments and secondary data analysis)\",\n",
            "    \"Contribution\": \"Theoretical and managerial contributions by providing insights into the differential roles of worker experience in human-AI collaboration.\",\n",
            "    \"Future Potential and Limitations\": \"The study suggests future research to explore the mechanisms that enhance user trust in AI and the dynamic interactions between AI and human workers. Limitations include the sample being drawn from one company, which may affect generalizability.\",\n",
            "    \"Keywords\": \"artificial intelligence, human-AI teaming, worker experience, productivity, healthcare, medical coding\",\n",
            "    \"Authors\": \"Weiguang Wang, Guodong (Gordon) Gao, Ritu Agarwal\",\n",
            "    \"Publication Information\": \"Management Science, Vol. 70, No. 9, September 2024, pp. 5753–5775, © 2023 INFORMS\",\n",
            "    \"Article Name\": \"Friend or Foe? Teaming Between Artificial Intelligence and Workers with Variation in Experience\"\n",
            "}\n",
            "Extracted Information:\n",
            "{\n",
            "    \"Context\": \"The study focuses on the healthcare industry, specifically on medical chart coding in a publicly traded company.\",\n",
            "    \"Research Question and Findings\": \"The main research question is how knowledge workers with different levels and types of experience can team with AI for productivity gains. The key findings are that AI benefits workers with greater task-based experience, but senior workers gain less from AI than their junior colleagues due to lower trust in AI.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"AI boosts productivity for all workers but more so for workers with greater task-based experience and less so for workers with greater time-based experience.\",\n",
            "        \"Human + AI Collaboration\": \"The study discusses AI as an augmentation tool for human workers, highlighting sentences with potential HCC codes for review by human coders.\"\n",
            "    },\n",
            "    \"Method\": \"Empirical Research (field experiments and secondary data analysis)\",\n",
            "    \"Contribution\": \"Theoretical and managerial contributions by providing insights into the differential roles of worker experience in human-AI collaboration.\",\n",
            "    \"Future Potential and Limitations\": \"The study suggests future research to explore the mechanisms that enhance user trust in AI and the dynamic interactions between AI and human workers. Limitations include the sample being drawn from one company, which may affect generalizability.\",\n",
            "    \"Keywords\": \"artificial intelligence, human-AI teaming, worker experience, productivity, healthcare, medical coding\",\n",
            "    \"Authors\": \"Weiguang Wang, Guodong (Gordon) Gao, Ritu Agarwal\",\n",
            "    \"Publication Information\": \"Management Science, Vol. 70, No. 9, September 2024, pp. 5753–5775, © 2023 INFORMS\",\n",
            "    \"Article Name\": \"Friend or Foe? Teaming Between Artificial Intelligence and Workers with Variation in Experience\"\n",
            "}\n",
            "Summary added to the summaries list.\n",
            "\n",
            "Processing /content/papers/32 article/ssrn-4312358.pdf ...\n",
            "GPT Original Output: {\n",
            "    \"Context\": \"The study is focused on the academic research industry, specifically using economics and finance as an illustrative example.\",\n",
            "    \"Research Question and Findings\": \"The main research question is to explore the role of AI, specifically ChatGPT, in enhancing academic performance. The key findings are that ChatGPT can significantly enhance academic research by assisting in data analysis, scenario generation, and communication of findings, but it has limitations such as dependence on data quality, lack of domain expertise, and ethical considerations.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"AI, particularly ChatGPT, has advantages in data analysis, scenario generation, and communication of findings, but it is limited by data quality, lack of domain expertise, and ethical considerations.\",\n",
            "        \"Human + AI Collaboration\": \"The study discusses using ChatGPT in conjunction with human analysis and interpretation to overcome its limitations and enhance research outcomes.\"\n",
            "    },\n",
            "    \"Method\": \"Conceptual/Case Study\",\n",
            "    \"Contribution\": \"Theoretical and managerial contributions by providing insights into the potential and limitations of AI in academic research.\",\n",
            "    \"Future Potential and Limitations\": \"Future research should address the limitations of AI tools like ChatGPT, such as data quality, domain expertise, and ethical considerations. The study also highlights the need for human oversight in using AI tools.\",\n",
            "    \"Keywords\": \"Artificial intelligence (AI), Natural language processing (NLP), ChatGPT, Research, Academic performance, Economics, Finance, Case study, Ethics\",\n",
            "    \"Authors\": \"Dr. Muneer M. Alshater\",\n",
            "    \"Publication Information\": \"Electronic copy available at: https://ssrn.com/abstract=43123581. Date: 27/12/2022\",\n",
            "    \"Article Name\": \"Exploring the Role of Artificial Intelligence in Enhancing Academic Performance: A Case Study of ChatGPT\"\n",
            "}\n",
            "Extracted Information:\n",
            "{\n",
            "    \"Context\": \"The study is focused on the academic research industry, specifically using economics and finance as an illustrative example.\",\n",
            "    \"Research Question and Findings\": \"The main research question is to explore the role of AI, specifically ChatGPT, in enhancing academic performance. The key findings are that ChatGPT can significantly enhance academic research by assisting in data analysis, scenario generation, and communication of findings, but it has limitations such as dependence on data quality, lack of domain expertise, and ethical considerations.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"AI, particularly ChatGPT, has advantages in data analysis, scenario generation, and communication of findings, but it is limited by data quality, lack of domain expertise, and ethical considerations.\",\n",
            "        \"Human + AI Collaboration\": \"The study discusses using ChatGPT in conjunction with human analysis and interpretation to overcome its limitations and enhance research outcomes.\"\n",
            "    },\n",
            "    \"Method\": \"Conceptual/Case Study\",\n",
            "    \"Contribution\": \"Theoretical and managerial contributions by providing insights into the potential and limitations of AI in academic research.\",\n",
            "    \"Future Potential and Limitations\": \"Future research should address the limitations of AI tools like ChatGPT, such as data quality, domain expertise, and ethical considerations. The study also highlights the need for human oversight in using AI tools.\",\n",
            "    \"Keywords\": \"Artificial intelligence (AI), Natural language processing (NLP), ChatGPT, Research, Academic performance, Economics, Finance, Case study, Ethics\",\n",
            "    \"Authors\": \"Dr. Muneer M. Alshater\",\n",
            "    \"Publication Information\": \"Electronic copy available at: https://ssrn.com/abstract=43123581. Date: 27/12/2022\",\n",
            "    \"Article Name\": \"Exploring the Role of Artificial Intelligence in Enhancing Academic Performance: A Case Study of ChatGPT\"\n",
            "}\n",
            "Summary added to the summaries list.\n",
            "\n",
            "Processing /content/papers/32 article/isre.2022.0152.pdf ...\n",
            "GPT Original Output: {\n",
            "    \"Context\": \"The study focuses on the customer service industry, specifically examining interactions with hybrid service agents that combine AI-based chatbots and human employees.\",\n",
            "    \"Research Question and Findings\": \"The main research question is whether firms should disclose human involvement in customer interactions with hybrid service agents, and how such disclosure affects customers and employees. The key findings are that disclosing human involvement leads customers to adopt a more human-oriented communication style, which increases employee workload. This effect is driven by customers' impression management concerns.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"The study highlights that customers communicate differently with AI chatbots compared to humans, using simpler and shorter messages with chatbots.\",\n",
            "        \"Human + AI Collaboration\": \"The research discusses the collaboration between AI chatbots and human employees in hybrid service agents, where AI handles routine queries and humans handle complex requests. The sequence of actions involves AI attempting to handle the request first, with human employees stepping in when AI is unable to respond.\"\n",
            "    },\n",
            "    \"Method\": \"Empirical Research (randomized field experiment and controlled online experiment)\",\n",
            "    \"Contribution\": \"Theoretical and managerial contributions by providing insights into customer behavior with hybrid service agents and the implications of disclosing human involvement.\",\n",
            "    \"Future Potential and Limitations\": \"The study suggests future research should focus on the employee perspective and the broader investigation of customer communication behavior. Limitations include the focus on text-based interactions and the potential changes in AI capabilities over time.\",\n",
            "    \"Keywords\": \"hybrid service agent, artificial intelligence, human involvement disclosure, communication style, chatbot, human–AI collaboration, customer service\",\n",
            "    \"Authors\": \"Ulrich Gnewuch, Stefan Morana, Oliver Hinz, Ralf Kellner, Alexander Maedche\",\n",
            "    \"Publication Information\": \"Information Systems Research, Published online in Articles in Advance 23 Aug 2023, Institute for Operations Research and the Management Sciences (INFORMS)\",\n",
            "    \"Article Name\": \"More Than a Bot? The Impact of Disclosing Human Involvement on Customer Interactions with Hybrid Service Agents\"\n",
            "}\n",
            "Extracted Information:\n",
            "{\n",
            "    \"Context\": \"The study focuses on the customer service industry, specifically examining interactions with hybrid service agents that combine AI-based chatbots and human employees.\",\n",
            "    \"Research Question and Findings\": \"The main research question is whether firms should disclose human involvement in customer interactions with hybrid service agents, and how such disclosure affects customers and employees. The key findings are that disclosing human involvement leads customers to adopt a more human-oriented communication style, which increases employee workload. This effect is driven by customers' impression management concerns.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"The study highlights that customers communicate differently with AI chatbots compared to humans, using simpler and shorter messages with chatbots.\",\n",
            "        \"Human + AI Collaboration\": \"The research discusses the collaboration between AI chatbots and human employees in hybrid service agents, where AI handles routine queries and humans handle complex requests. The sequence of actions involves AI attempting to handle the request first, with human employees stepping in when AI is unable to respond.\"\n",
            "    },\n",
            "    \"Method\": \"Empirical Research (randomized field experiment and controlled online experiment)\",\n",
            "    \"Contribution\": \"Theoretical and managerial contributions by providing insights into customer behavior with hybrid service agents and the implications of disclosing human involvement.\",\n",
            "    \"Future Potential and Limitations\": \"The study suggests future research should focus on the employee perspective and the broader investigation of customer communication behavior. Limitations include the focus on text-based interactions and the potential changes in AI capabilities over time.\",\n",
            "    \"Keywords\": \"hybrid service agent, artificial intelligence, human involvement disclosure, communication style, chatbot, human–AI collaboration, customer service\",\n",
            "    \"Authors\": \"Ulrich Gnewuch, Stefan Morana, Oliver Hinz, Ralf Kellner, Alexander Maedche\",\n",
            "    \"Publication Information\": \"Information Systems Research, Published online in Articles in Advance 23 Aug 2023, Institute for Operations Research and the Management Sciences (INFORMS)\",\n",
            "    \"Article Name\": \"More Than a Bot? The Impact of Disclosing Human Involvement on Customer Interactions with Hybrid Service Agents\"\n",
            "}\n",
            "Summary added to the summaries list.\n",
            "\n",
            "Processing /content/papers/32 article/retrieve-6.pdf ...\n",
            "GPT Original Output: {\n",
            "    \"Context\": \"The study focuses on the supply chain industry, specifically examining the effects of AI automation on retailer order decisions in a decentralized supply chain.\",\n",
            "    \"Research Question and Findings\": \"The main research question is how AI automation affects ordering decisions and expected profits of newsvendors and suppliers in supply chains governed by wholesale price contracts. Key findings include that automation can lead to a lose-lose outcome where both retailer and supplier are worse off, and regret bias can either benefit or harm the supply chain depending on profit margins.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"AI automation can reduce decision bias but may not always lead to higher expected profits for retailers. Excessive automation can be detrimental, highlighting the importance of human judgment.\",\n",
            "        \"Human + AI Collaboration\": \"The study discusses the replacement of human managers with AI systems for order decisions, analyzing the impact on supply chain dynamics and profits.\"\n",
            "    },\n",
            "    \"Method\": \"Modeling (including stylized models)\",\n",
            "    \"Contribution\": \"Theoretical\",\n",
            "    \"Future Potential and Limitations\": \"Future research could explore other factors affecting AI adoption, such as labor cost reduction and ethical issues. Limitations include the focus on regret bias without considering other potential biases.\",\n",
            "    \"Keywords\": \"managerial bias, human-machine reconcile, emotion, Industry 4.0, Artificial Intelligence\",\n",
            "    \"Authors\": \"Meng Li, Tao Li\",\n",
            "    \"Publication Information\": \"Production and Operations Management, Vol. 31, No. 1, January 2022, pp. 83–97\",\n",
            "    \"Article Name\": \"AI Automation and Retailer Regret in Supply Chains\"\n",
            "}\n",
            "Extracted Information:\n",
            "{\n",
            "    \"Context\": \"The study focuses on the supply chain industry, specifically examining the effects of AI automation on retailer order decisions in a decentralized supply chain.\",\n",
            "    \"Research Question and Findings\": \"The main research question is how AI automation affects ordering decisions and expected profits of newsvendors and suppliers in supply chains governed by wholesale price contracts. Key findings include that automation can lead to a lose-lose outcome where both retailer and supplier are worse off, and regret bias can either benefit or harm the supply chain depending on profit margins.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"AI automation can reduce decision bias but may not always lead to higher expected profits for retailers. Excessive automation can be detrimental, highlighting the importance of human judgment.\",\n",
            "        \"Human + AI Collaboration\": \"The study discusses the replacement of human managers with AI systems for order decisions, analyzing the impact on supply chain dynamics and profits.\"\n",
            "    },\n",
            "    \"Method\": \"Modeling (including stylized models)\",\n",
            "    \"Contribution\": \"Theoretical\",\n",
            "    \"Future Potential and Limitations\": \"Future research could explore other factors affecting AI adoption, such as labor cost reduction and ethical issues. Limitations include the focus on regret bias without considering other potential biases.\",\n",
            "    \"Keywords\": \"managerial bias, human-machine reconcile, emotion, Industry 4.0, Artificial Intelligence\",\n",
            "    \"Authors\": \"Meng Li, Tao Li\",\n",
            "    \"Publication Information\": \"Production and Operations Management, Vol. 31, No. 1, January 2022, pp. 83–97\",\n",
            "    \"Article Name\": \"AI Automation and Retailer Regret in Supply Chains\"\n",
            "}\n",
            "Summary added to the summaries list.\n",
            "\n",
            "Processing /content/papers/32 article/han-et-al-2022-bots-with-feelings-should-ai-agents-express-positive-emotion-in-customer-service.pdf ...\n",
            "GPT Original Output: {\n",
            "    \"Context\": \"The study is focused on the customer service industry, specifically examining the role of AI agents expressing positive emotion during customer interactions.\",\n",
            "    \"Research Question and Findings\": \"The main research question is how, when, and why an AI agent's expression of positive emotion influences customers' service evaluations. The key findings suggest that AI-expressed positive emotion is less effective than human-expressed emotion due to expectation–disconfirmation. However, the effect varies based on customers' relationship norm orientation.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"The research highlights that human-expressed positive emotion is more effective in enhancing service evaluations than AI-expressed emotion due to expectation–disconfirmation.\",\n",
            "        \"Human + AI Collaboration\": \"The study does not explicitly discuss human and AI collaboration but focuses on the comparative impact of AI versus human emotional expressions.\"\n",
            "    },\n",
            "    \"Method\": \"Empirical Research (laboratory experiments)\",\n",
            "    \"Contribution\": \"Theoretical\",\n",
            "    \"Future Potential and Limitations\": \"Future research could explore other factors that influence the impact of AI-expressed emotion, such as cultural differences or different service contexts. Limitations include the focus on text-based chatbots and the specific scenarios used in experiments.\",\n",
            "    \"Keywords\": \"emotional artificial intelligence, conversational agent, chatbot, customer service, emotional contagion, expectation–disconfirmation, relationship norm orientation\",\n",
            "    \"Authors\": \"Elizabeth Han, Dezhi Yin, Han Zhang\",\n",
            "    \"Publication Information\": \"Information Systems Research, Vol. 34, No. 3, September 2023, pp. 1296–1311\",\n",
            "    \"Article Name\": \"Bots with Feelings: Should AI Agents Express Positive Emotion in Customer Service?\"\n",
            "}\n",
            "Extracted Information:\n",
            "{\n",
            "    \"Context\": \"The study is focused on the customer service industry, specifically examining the role of AI agents expressing positive emotion during customer interactions.\",\n",
            "    \"Research Question and Findings\": \"The main research question is how, when, and why an AI agent's expression of positive emotion influences customers' service evaluations. The key findings suggest that AI-expressed positive emotion is less effective than human-expressed emotion due to expectation–disconfirmation. However, the effect varies based on customers' relationship norm orientation.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"The research highlights that human-expressed positive emotion is more effective in enhancing service evaluations than AI-expressed emotion due to expectation–disconfirmation.\",\n",
            "        \"Human + AI Collaboration\": \"The study does not explicitly discuss human and AI collaboration but focuses on the comparative impact of AI versus human emotional expressions.\"\n",
            "    },\n",
            "    \"Method\": \"Empirical Research (laboratory experiments)\",\n",
            "    \"Contribution\": \"Theoretical\",\n",
            "    \"Future Potential and Limitations\": \"Future research could explore other factors that influence the impact of AI-expressed emotion, such as cultural differences or different service contexts. Limitations include the focus on text-based chatbots and the specific scenarios used in experiments.\",\n",
            "    \"Keywords\": \"emotional artificial intelligence, conversational agent, chatbot, customer service, emotional contagion, expectation–disconfirmation, relationship norm orientation\",\n",
            "    \"Authors\": \"Elizabeth Han, Dezhi Yin, Han Zhang\",\n",
            "    \"Publication Information\": \"Information Systems Research, Vol. 34, No. 3, September 2023, pp. 1296–1311\",\n",
            "    \"Article Name\": \"Bots with Feelings: Should AI Agents Express Positive Emotion in Customer Service?\"\n",
            "}\n",
            "Summary added to the summaries list.\n",
            "\n",
            "Processing /content/papers/32 article/SSRN-id3606633.pdf ...\n",
            "GPT Original Output: {\n",
            "    \"Context\": \"The study focuses on the integration of human judgment with prediction algorithms, specifically in the context of forecasting surgery durations in hospitals.\",\n",
            "    \"Research Question and Findings\": \"The main research question is whether eliciting private information adjustments (PIA) from humans can improve the accuracy of prediction algorithms compared to direct forecasts (DF). The key findings are that PIA leads to more accurate predictions than DF when human random error is present, and this advantage is influenced by the complexity of public and private information.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"Humans have access to private information that algorithms do not, which can enhance prediction accuracy when used as inputs to algorithms. However, humans are prone to random errors when processing information.\",\n",
            "        \"Human + AI Collaboration\": \"The study discusses a collaborative approach where human judgments are used as inputs to prediction algorithms, specifically through eliciting private information adjustments (PIA) rather than direct forecasts (DF).\"\n",
            "    },\n",
            "    \"Method\": \"Empirical Research (laboratory experiments)\",\n",
            "    \"Contribution\": \"Theoretical and methodological contributions by proposing a new elicitation method (PIA) and demonstrating its effectiveness in improving prediction accuracy.\",\n",
            "    \"Future Potential and Limitations\": \"Future research should explore field experiments to validate the findings and investigate the best ways to formulate PIA questions. Limitations include the laboratory setting and the assumption of linear relationships.\",\n",
            "    \"Keywords\": \"laboratory experiments, behavioral operations, random error, elicitation, forecasting, prediction, discretion, expert input, private information, judgment, aggregation\",\n",
            "    \"Authors\": \"Rouba Ibrahim, Song-Hee Kim, Jordan Tong\",\n",
            "    \"Publication Information\": \"Electronic copy available at: https://ssrn.com/abstract=36066332, August 3, 2020\",\n",
            "    \"Article Name\": \"Eliciting Human Judgment for Prediction Algorithms\"\n",
            "}\n",
            "Extracted Information:\n",
            "{\n",
            "    \"Context\": \"The study focuses on the integration of human judgment with prediction algorithms, specifically in the context of forecasting surgery durations in hospitals.\",\n",
            "    \"Research Question and Findings\": \"The main research question is whether eliciting private information adjustments (PIA) from humans can improve the accuracy of prediction algorithms compared to direct forecasts (DF). The key findings are that PIA leads to more accurate predictions than DF when human random error is present, and this advantage is influenced by the complexity of public and private information.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"Humans have access to private information that algorithms do not, which can enhance prediction accuracy when used as inputs to algorithms. However, humans are prone to random errors when processing information.\",\n",
            "        \"Human + AI Collaboration\": \"The study discusses a collaborative approach where human judgments are used as inputs to prediction algorithms, specifically through eliciting private information adjustments (PIA) rather than direct forecasts (DF).\"\n",
            "    },\n",
            "    \"Method\": \"Empirical Research (laboratory experiments)\",\n",
            "    \"Contribution\": \"Theoretical and methodological contributions by proposing a new elicitation method (PIA) and demonstrating its effectiveness in improving prediction accuracy.\",\n",
            "    \"Future Potential and Limitations\": \"Future research should explore field experiments to validate the findings and investigate the best ways to formulate PIA questions. Limitations include the laboratory setting and the assumption of linear relationships.\",\n",
            "    \"Keywords\": \"laboratory experiments, behavioral operations, random error, elicitation, forecasting, prediction, discretion, expert input, private information, judgment, aggregation\",\n",
            "    \"Authors\": \"Rouba Ibrahim, Song-Hee Kim, Jordan Tong\",\n",
            "    \"Publication Information\": \"Electronic copy available at: https://ssrn.com/abstract=36066332, August 3, 2020\",\n",
            "    \"Article Name\": \"Eliciting Human Judgment for Prediction Algorithms\"\n",
            "}\n",
            "Summary added to the summaries list.\n",
            "\n",
            "Processing /content/papers/32 article/cui-et-al-2021-ai-and-procurement.pdf ...\n",
            "GPT Original Output: {\n",
            "    \"Context\": \"The study is focused on the procurement industry, specifically examining how AI affects suppliers' price quoting strategies.\",\n",
            "    \"Research Question and Findings\": \"The main research question is how buyers' use of AI affects suppliers' price quoting strategies. The key findings are that automation without smartness leads to higher price quotes for chatbot buyers compared to human buyers, but signaling the use of a smart AI recommendation system can reduce the price quotes for chatbot buyers. The study concludes that AI delivers the most value when both automation and smartness are used together.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"The study highlights that without smart controls, chatbot buyers receive higher price quotes than human buyers, indicating a disadvantage for AI in this context. However, AI can outperform humans when smart recommendations are used.\",\n",
            "        \"Human + AI Collaboration\": \"The study discusses the collaboration where AI is used for automation and smartness in procurement. It emphasizes that AI delivers the most value when both automation and smartness are used together, suggesting a sequence where smartness should be developed before high levels of automation.\"\n",
            "    },\n",
            "    \"Method\": \"Empirical Research (field experiments)\",\n",
            "    \"Contribution\": \"Managerial\",\n",
            "    \"Future Potential and Limitations\": \"The study suggests that future research should explore the implementation of AI strategies in procurement, particularly focusing on enhancing smart controls before automation. A limitation is that the study focuses on commodity products, and the effects might differ for non-commodity products.\",\n",
            "    \"Keywords\": \"artificial intelligence, procurement, wholesale pricing, automation, smartness\",\n",
            "    \"Authors\": \"Ruomeng Cui, Meng Li, Shichen Zhang\",\n",
            "    \"Publication Information\": \"Manufacturing & Service Operations Management, Vol. 24, No. 2, March–April 2022, pp. 691–706, © 2021 INFORMS\",\n",
            "    \"Article Name\": \"AI and Procurement\"\n",
            "}\n",
            "Extracted Information:\n",
            "{\n",
            "    \"Context\": \"The study is focused on the procurement industry, specifically examining how AI affects suppliers' price quoting strategies.\",\n",
            "    \"Research Question and Findings\": \"The main research question is how buyers' use of AI affects suppliers' price quoting strategies. The key findings are that automation without smartness leads to higher price quotes for chatbot buyers compared to human buyers, but signaling the use of a smart AI recommendation system can reduce the price quotes for chatbot buyers. The study concludes that AI delivers the most value when both automation and smartness are used together.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"The study highlights that without smart controls, chatbot buyers receive higher price quotes than human buyers, indicating a disadvantage for AI in this context. However, AI can outperform humans when smart recommendations are used.\",\n",
            "        \"Human + AI Collaboration\": \"The study discusses the collaboration where AI is used for automation and smartness in procurement. It emphasizes that AI delivers the most value when both automation and smartness are used together, suggesting a sequence where smartness should be developed before high levels of automation.\"\n",
            "    },\n",
            "    \"Method\": \"Empirical Research (field experiments)\",\n",
            "    \"Contribution\": \"Managerial\",\n",
            "    \"Future Potential and Limitations\": \"The study suggests that future research should explore the implementation of AI strategies in procurement, particularly focusing on enhancing smart controls before automation. A limitation is that the study focuses on commodity products, and the effects might differ for non-commodity products.\",\n",
            "    \"Keywords\": \"artificial intelligence, procurement, wholesale pricing, automation, smartness\",\n",
            "    \"Authors\": \"Ruomeng Cui, Meng Li, Shichen Zhang\",\n",
            "    \"Publication Information\": \"Manufacturing & Service Operations Management, Vol. 24, No. 2, March–April 2022, pp. 691–706, © 2021 INFORMS\",\n",
            "    \"Article Name\": \"AI and Procurement\"\n",
            "}\n",
            "Summary added to the summaries list.\n",
            "\n",
            "Processing /content/papers/32 article/2209.01874v4.pdf ...\n",
            "GPT Original Output: {\n",
            "    \"Context\": \"The study focuses on high-stake decision-making processes where a human operator receives recommendations from an algorithm but is the ultimate decision maker.\",\n",
            "    \"Research Question and Findings\": \"The main research question is how to adjust algorithmic recommendations given the fact that decision makers will partially implement them. The key findings include the development of an adherence-aware optimization framework that accounts for partial adherence and improves upon baseline policies.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"The study highlights that human deviations from algorithmic recommendations can lead to poor performance, emphasizing the importance of accounting for partial adherence.\",\n",
            "        \"Human + AI Collaboration\": \"The research discusses a framework where the algorithm provides recommendations, and the human decision maker has the discretion to override them. The collaboration aims to create recommendation policies that are immune to human deviations.\"\n",
            "    },\n",
            "    \"Method\": \"Modeling (including stylized or Operations Research (OR) models)\",\n",
            "    \"Contribution\": \"Theoretical\",\n",
            "    \"Future Potential and Limitations\": \"The study suggests future research could explore more complex behavioral models behind partial adherence and the integration of these models into algorithmic recommendations. Limitations include the assumption of known adherence levels and baseline policies.\",\n",
            "    \"Keywords\": \"Expert-in-the-loop systems, Prescriptive analytics, Recommender systems, Discretion, Markov Decision Processes\",\n",
            "    \"Authors\": \"Julien Grand-Clément, Jean Pauphilet\",\n",
            "    \"Publication Information\": \"arXiv preprint arXiv:2209.01874v4 [cs.HC] 9 Dec 2023\",\n",
            "    \"Article Name\": \"The Best Decisions Are Not the Best Advice: Making Adherence-Aware Recommendations\"\n",
            "}\n",
            "Extracted Information:\n",
            "{\n",
            "    \"Context\": \"The study focuses on high-stake decision-making processes where a human operator receives recommendations from an algorithm but is the ultimate decision maker.\",\n",
            "    \"Research Question and Findings\": \"The main research question is how to adjust algorithmic recommendations given the fact that decision makers will partially implement them. The key findings include the development of an adherence-aware optimization framework that accounts for partial adherence and improves upon baseline policies.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"The study highlights that human deviations from algorithmic recommendations can lead to poor performance, emphasizing the importance of accounting for partial adherence.\",\n",
            "        \"Human + AI Collaboration\": \"The research discusses a framework where the algorithm provides recommendations, and the human decision maker has the discretion to override them. The collaboration aims to create recommendation policies that are immune to human deviations.\"\n",
            "    },\n",
            "    \"Method\": \"Modeling (including stylized or Operations Research (OR) models)\",\n",
            "    \"Contribution\": \"Theoretical\",\n",
            "    \"Future Potential and Limitations\": \"The study suggests future research could explore more complex behavioral models behind partial adherence and the integration of these models into algorithmic recommendations. Limitations include the assumption of known adherence levels and baseline policies.\",\n",
            "    \"Keywords\": \"Expert-in-the-loop systems, Prescriptive analytics, Recommender systems, Discretion, Markov Decision Processes\",\n",
            "    \"Authors\": \"Julien Grand-Clément, Jean Pauphilet\",\n",
            "    \"Publication Information\": \"arXiv preprint arXiv:2209.01874v4 [cs.HC] 9 Dec 2023\",\n",
            "    \"Article Name\": \"The Best Decisions Are Not the Best Advice: Making Adherence-Aware Recommendations\"\n",
            "}\n",
            "Summary added to the summaries list.\n",
            "\n",
            "Processing /content/papers/32 article/ssrn-4737265.pdf ...\n",
            "GPT Original Output: {\n",
            "    \"Context\": \"The study focuses on the broader, conceptual scope of AI versus human cognition and causal reasoning.\",\n",
            "    \"Research Question and Findings\": \"The main research question is whether AI can generate genuine novelty and new knowledge, and if AI and computational models of cognition will replace human decision-making under uncertainty. The key findings suggest that AI's data-based prediction is different from human theory-based causal logic and reasoning, with human cognition being forward-looking and capable of generating genuine novelty.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"The research highlights that AI is backward-looking and imitative, focusing on data-based prediction, while human cognition is forward-looking, capable of generating novelty through theory-based causal reasoning.\",\n",
            "        \"Human + AI Collaboration\": \"The study does not focus on specific types of collaboration between humans and AI but emphasizes the distinct roles and capabilities of each.\"\n",
            "    },\n",
            "    \"Method\": \"Conceptual/Case Study\",\n",
            "    \"Contribution\": \"Theoretical\",\n",
            "    \"Future Potential and Limitations\": \"The study suggests future research opportunities in understanding how AI tools might be utilized by humans to create new value, developing taxonomies of human versus AI capabilities, and exploring the nature of human cognition beyond computational models. Limitations include the current state of AI and its inability to replicate human causal reasoning.\",\n",
            "    \"Keywords\": \"cognition, artificial intelligence, prediction, causal reasoning, decision making, strategy, theory-based view\",\n",
            "    \"Authors\": \"Teppo Felin, Matthias Holweg\",\n",
            "    \"Publication Information\": \"Presented at the Strategy Science 'Theory-Based View' conference at Bocconi University, Harvard Business School, Aalto University, and the University of Illinois Urbana-Champaign.\",\n",
            "    \"Article Name\": \"Theory Is All You Need: AI, Human Cognition, and Causal Reasoning\"\n",
            "}\n",
            "Extracted Information:\n",
            "{\n",
            "    \"Context\": \"The study focuses on the broader, conceptual scope of AI versus human cognition and causal reasoning.\",\n",
            "    \"Research Question and Findings\": \"The main research question is whether AI can generate genuine novelty and new knowledge, and if AI and computational models of cognition will replace human decision-making under uncertainty. The key findings suggest that AI's data-based prediction is different from human theory-based causal logic and reasoning, with human cognition being forward-looking and capable of generating genuine novelty.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"The research highlights that AI is backward-looking and imitative, focusing on data-based prediction, while human cognition is forward-looking, capable of generating novelty through theory-based causal reasoning.\",\n",
            "        \"Human + AI Collaboration\": \"The study does not focus on specific types of collaboration between humans and AI but emphasizes the distinct roles and capabilities of each.\"\n",
            "    },\n",
            "    \"Method\": \"Conceptual/Case Study\",\n",
            "    \"Contribution\": \"Theoretical\",\n",
            "    \"Future Potential and Limitations\": \"The study suggests future research opportunities in understanding how AI tools might be utilized by humans to create new value, developing taxonomies of human versus AI capabilities, and exploring the nature of human cognition beyond computational models. Limitations include the current state of AI and its inability to replicate human causal reasoning.\",\n",
            "    \"Keywords\": \"cognition, artificial intelligence, prediction, causal reasoning, decision making, strategy, theory-based view\",\n",
            "    \"Authors\": \"Teppo Felin, Matthias Holweg\",\n",
            "    \"Publication Information\": \"Presented at the Strategy Science 'Theory-Based View' conference at Bocconi University, Harvard Business School, Aalto University, and the University of Illinois Urbana-Champaign.\",\n",
            "    \"Article Name\": \"Theory Is All You Need: AI, Human Cognition, and Causal Reasoning\"\n",
            "}\n",
            "Summary added to the summaries list.\n",
            "\n",
            "Processing /content/papers/32 article/1-s2.0-S2095809919301535-main.pdf ...\n",
            "GPT Original Output: {\n",
            "    \"Context\": \"The study is focused on the healthcare industry, specifically on the application of artificial intelligence in biomedicine, including disease diagnostics, living assistance, biomedical information processing, and biomedical research.\",\n",
            "    \"Research Question and Findings\": \"The main research question is to review the latest developments and applications of AI in biomedicine and to illustrate its potential through prediction case studies. The key findings are that AI is still in its early stages in biomedicine but has tremendous potential to improve disease diagnostics, prediction, and overall healthcare outcomes.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"The research highlights the advantages of AI in processing large datasets, improving diagnostic accuracy, and predicting medical conditions, which can outperform human capabilities in specific contexts.\",\n",
            "        \"Human + AI Collaboration\": \"The study discusses the collaboration between humans and AI in healthcare, where AI assists healthcare professionals by providing diagnostic support and predictive analytics, enhancing the decision-making process.\"\n",
            "    },\n",
            "    \"Method\": \"Conceptual/Case Study\",\n",
            "    \"Contribution\": \"Theoretical and managerial contributions by providing a comprehensive review of AI applications in healthcare and suggesting future directions for research and development.\",\n",
            "    \"Future Potential and Limitations\": \"The study recommends further research in AI applications in biomedicine, emphasizing the need for improved feature extraction, electrode selection, hardware implementation, and deep learning algorithms. Limitations include the early stage of AI development in biomedicine and the need for more extensive datasets and validation.\",\n",
            "    \"Keywords\": \"Artificial intelligence, Machine learning, Deep learning, Neural network, Biomedical research, Healthcare applications, Epileptic seizure, Urinary bladder filling\",\n",
            "    \"Authors\": \"Guoguang Rong, Arnaldo Mendez, Elie Bou Assi, Bo Zhao, Mohamad Sawan\",\n",
            "    \"Publication Information\": \"Published in Engineering, Volume 6, 2020, Pages 291-301\",\n",
            "    \"Article Name\": \"Artificial Intelligence in Healthcare: Review and Prediction Case Studies\"\n",
            "}\n",
            "Extracted Information:\n",
            "{\n",
            "    \"Context\": \"The study is focused on the healthcare industry, specifically on the application of artificial intelligence in biomedicine, including disease diagnostics, living assistance, biomedical information processing, and biomedical research.\",\n",
            "    \"Research Question and Findings\": \"The main research question is to review the latest developments and applications of AI in biomedicine and to illustrate its potential through prediction case studies. The key findings are that AI is still in its early stages in biomedicine but has tremendous potential to improve disease diagnostics, prediction, and overall healthcare outcomes.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"The research highlights the advantages of AI in processing large datasets, improving diagnostic accuracy, and predicting medical conditions, which can outperform human capabilities in specific contexts.\",\n",
            "        \"Human + AI Collaboration\": \"The study discusses the collaboration between humans and AI in healthcare, where AI assists healthcare professionals by providing diagnostic support and predictive analytics, enhancing the decision-making process.\"\n",
            "    },\n",
            "    \"Method\": \"Conceptual/Case Study\",\n",
            "    \"Contribution\": \"Theoretical and managerial contributions by providing a comprehensive review of AI applications in healthcare and suggesting future directions for research and development.\",\n",
            "    \"Future Potential and Limitations\": \"The study recommends further research in AI applications in biomedicine, emphasizing the need for improved feature extraction, electrode selection, hardware implementation, and deep learning algorithms. Limitations include the early stage of AI development in biomedicine and the need for more extensive datasets and validation.\",\n",
            "    \"Keywords\": \"Artificial intelligence, Machine learning, Deep learning, Neural network, Biomedical research, Healthcare applications, Epileptic seizure, Urinary bladder filling\",\n",
            "    \"Authors\": \"Guoguang Rong, Arnaldo Mendez, Elie Bou Assi, Bo Zhao, Mohamad Sawan\",\n",
            "    \"Publication Information\": \"Published in Engineering, Volume 6, 2020, Pages 291-301\",\n",
            "    \"Article Name\": \"Artificial Intelligence in Healthcare: Review and Prediction Case Studies\"\n",
            "}\n",
            "Summary added to the summaries list.\n",
            "\n",
            "Processing /content/papers/32 article/waardenburg-et-al-2021-in-the-land-of-the-blind-the-one-eyed-man-is-king-knowledge-brokerage-in-the-age-of-learning.pdf ...\n",
            "GPT Original Output: {\n",
            "    \"Context\": \"The study is focused on the implementation of a learning algorithm by the Dutch police to predict crime incidents, specifically examining the role of knowledge brokers in this context.\",\n",
            "    \"Research Question and Findings\": \"The main research question is how knowledge brokers translate algorithmic predictions when they cannot understand how these are generated. The key findings indicate that knowledge brokers enact different translation practices over time, evolving from messengers to interpreters and finally to curators, often substituting algorithmic predictions with their own judgments due to the opaque nature of machine learning.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"The study highlights the challenges humans face in understanding and interpreting opaque algorithmic predictions, emphasizing the limitations of human reasoning in comprehending machine learning processes.\",\n",
            "        \"Human + AI Collaboration\": \"The research discusses the role of intelligence officers as algorithmic brokers who attempt to bridge the gap between machine learning predictions and police management, highlighting the evolving nature of their collaboration.\"\n",
            "    },\n",
            "    \"Method\": \"Empirical Research (31-month ethnographic study)\",\n",
            "    \"Contribution\": \"Theoretical and managerial contributions by providing insights into the dynamic nature of algorithmic brokerage work and its implications for knowledge translation in organizations.\",\n",
            "    \"Future Potential and Limitations\": \"The study suggests the need for further research into the roles and skills required for effective algorithmic brokerage, as well as the implications of opaque machine learning for organizational decision-making. Limitations include the focus on a specific organizational context and the challenges of generalizing findings.\",\n",
            "    \"Keywords\": \"learning algorithms, artificial intelligence, algorithmic brokers, knowledge brokerage, knowledge sharing, knowledge translation\",\n",
            "    \"Authors\": \"Lauren Waardenburg, Marleen Huysman, Anastasia V. Sergeeva\",\n",
            "    \"Publication Information\": \"Organization Science, Vol. 33, No. 1, January–February 2022, pp. 59–82, ISSN 1047-7039 (print), ISSN 1526-5455 (online)\",\n",
            "    \"Article Name\": \"In the Land of the Blind, the One-Eyed Man Is King: Knowledge Brokerage in the Age of Learning Algorithms\"\n",
            "}\n",
            "Extracted Information:\n",
            "{\n",
            "    \"Context\": \"The study is focused on the implementation of a learning algorithm by the Dutch police to predict crime incidents, specifically examining the role of knowledge brokers in this context.\",\n",
            "    \"Research Question and Findings\": \"The main research question is how knowledge brokers translate algorithmic predictions when they cannot understand how these are generated. The key findings indicate that knowledge brokers enact different translation practices over time, evolving from messengers to interpreters and finally to curators, often substituting algorithmic predictions with their own judgments due to the opaque nature of machine learning.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"The study highlights the challenges humans face in understanding and interpreting opaque algorithmic predictions, emphasizing the limitations of human reasoning in comprehending machine learning processes.\",\n",
            "        \"Human + AI Collaboration\": \"The research discusses the role of intelligence officers as algorithmic brokers who attempt to bridge the gap between machine learning predictions and police management, highlighting the evolving nature of their collaboration.\"\n",
            "    },\n",
            "    \"Method\": \"Empirical Research (31-month ethnographic study)\",\n",
            "    \"Contribution\": \"Theoretical and managerial contributions by providing insights into the dynamic nature of algorithmic brokerage work and its implications for knowledge translation in organizations.\",\n",
            "    \"Future Potential and Limitations\": \"The study suggests the need for further research into the roles and skills required for effective algorithmic brokerage, as well as the implications of opaque machine learning for organizational decision-making. Limitations include the focus on a specific organizational context and the challenges of generalizing findings.\",\n",
            "    \"Keywords\": \"learning algorithms, artificial intelligence, algorithmic brokers, knowledge brokerage, knowledge sharing, knowledge translation\",\n",
            "    \"Authors\": \"Lauren Waardenburg, Marleen Huysman, Anastasia V. Sergeeva\",\n",
            "    \"Publication Information\": \"Organization Science, Vol. 33, No. 1, January–February 2022, pp. 59–82, ISSN 1047-7039 (print), ISSN 1526-5455 (online)\",\n",
            "    \"Article Name\": \"In the Land of the Blind, the One-Eyed Man Is King: Knowledge Brokerage in the Age of Learning Algorithms\"\n",
            "}\n",
            "Summary added to the summaries list.\n",
            "\n",
            "Processing /content/papers/32 article/BJET_Artificial%20Intelligence%20with%20Multimodal%20Data%20in%20the%20Service%20of%20Human%20Decision.pdf ...\n",
            "GPT Original Output: {\n",
            "    \"Context\": \"The study is focused on the education industry, specifically in the context of debate tutoring.\",\n",
            "    \"Research Question and Findings\": \"The main research question is how AI can augment human intelligence in decision-making processes in education. The key findings are that multimodal data leads to more accurate classification models for expert tutors' decisions about social and emotional aspects of tutoring.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"The study highlights that AI should support human decision-making rather than replace it, emphasizing the augmentation of human intelligence.\",\n",
            "        \"Human + AI Collaboration\": \"The study discusses the use of AI to provide transparent classification models to support educators in reflecting on their decision-making processes.\"\n",
            "    },\n",
            "    \"Method\": \"Conceptual/Case Study\",\n",
            "    \"Contribution\": \"Managerial\",\n",
            "    \"Future Potential and Limitations\": \"The study is limited by its small sample size and specific context. Future research should explore different decision contexts and investigate the adoption of decision support tools by educators.\",\n",
            "    \"Keywords\": \"AI in Education, Decision-making, Multimodality, Tutor Evaluations\",\n",
            "    \"Authors\": \"Mutlu Cukurova, Carmel Kent, Rosemary Luckin\",\n",
            "    \"Publication Information\": \"British Journal of Educational Technology, 50(6), pp. 3032–3046, 2019\",\n",
            "    \"Article Name\": \"Artificial intelligence and multimodal data in the service of human decision-making: A case study in debate tutoring\"\n",
            "}\n",
            "Extracted Information:\n",
            "{\n",
            "    \"Context\": \"The study is focused on the education industry, specifically in the context of debate tutoring.\",\n",
            "    \"Research Question and Findings\": \"The main research question is how AI can augment human intelligence in decision-making processes in education. The key findings are that multimodal data leads to more accurate classification models for expert tutors' decisions about social and emotional aspects of tutoring.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"The study highlights that AI should support human decision-making rather than replace it, emphasizing the augmentation of human intelligence.\",\n",
            "        \"Human + AI Collaboration\": \"The study discusses the use of AI to provide transparent classification models to support educators in reflecting on their decision-making processes.\"\n",
            "    },\n",
            "    \"Method\": \"Conceptual/Case Study\",\n",
            "    \"Contribution\": \"Managerial\",\n",
            "    \"Future Potential and Limitations\": \"The study is limited by its small sample size and specific context. Future research should explore different decision contexts and investigate the adoption of decision support tools by educators.\",\n",
            "    \"Keywords\": \"AI in Education, Decision-making, Multimodality, Tutor Evaluations\",\n",
            "    \"Authors\": \"Mutlu Cukurova, Carmel Kent, Rosemary Luckin\",\n",
            "    \"Publication Information\": \"British Journal of Educational Technology, 50(6), pp. 3032–3046, 2019\",\n",
            "    \"Article Name\": \"Artificial intelligence and multimodal data in the service of human decision-making: A case study in debate tutoring\"\n",
            "}\n",
            "Summary added to the summaries list.\n",
            "\n",
            "Processing /content/papers/32 article/ESMT-20-02.pdf ...\n",
            "GPT Original Output: {\n",
            "    \"Context\": \"The study focuses on decision-making under cognitive limitations, relevant to various industries such as healthcare, legal services, and finance.\",\n",
            "    \"Research Question and Findings\": \"The main research question is: What is the impact of machine-based predictions on human judgment? The study finds that machine input improves overall decision accuracy but can increase certain types of errors, like false positives, and may lead to more cognitive effort by humans.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"AI can perform specific tasks with high accuracy due to immense computing power, while humans are flexible and adaptive but limited by cognitive capacity.\",\n",
            "        \"Human + AI Collaboration\": \"The study discusses collaboration where AI provides accurate information at no cognitive cost, and humans integrate this with their domain knowledge.\"\n",
            "    },\n",
            "    \"Method\": \"Modeling (rational inattention framework)\",\n",
            "    \"Contribution\": \"Theoretical\",\n",
            "    \"Future Potential and Limitations\": \"Future research could explore different decision environments and the implications of varying cognitive costs. Limitations include the static nature of the model and the assumption of perfect machine accuracy.\",\n",
            "    \"Keywords\": \"machine-learning, rational inattention, human-machine collaboration, cognitive effort\",\n",
            "    \"Authors\": \"Tamer Boyaci, Caner Canyakmaz, Francis de Véricourt\",\n",
            "    \"Publication Information\": \"ESMT Working Paper 20-02, November 30, 2020\",\n",
            "    \"Article Name\": \"Human and Machine: The Impact of Machine Input on Decision-Making Under Cognitive Limitations\"\n",
            "}\n",
            "Extracted Information:\n",
            "{\n",
            "    \"Context\": \"The study focuses on decision-making under cognitive limitations, relevant to various industries such as healthcare, legal services, and finance.\",\n",
            "    \"Research Question and Findings\": \"The main research question is: What is the impact of machine-based predictions on human judgment? The study finds that machine input improves overall decision accuracy but can increase certain types of errors, like false positives, and may lead to more cognitive effort by humans.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"AI can perform specific tasks with high accuracy due to immense computing power, while humans are flexible and adaptive but limited by cognitive capacity.\",\n",
            "        \"Human + AI Collaboration\": \"The study discusses collaboration where AI provides accurate information at no cognitive cost, and humans integrate this with their domain knowledge.\"\n",
            "    },\n",
            "    \"Method\": \"Modeling (rational inattention framework)\",\n",
            "    \"Contribution\": \"Theoretical\",\n",
            "    \"Future Potential and Limitations\": \"Future research could explore different decision environments and the implications of varying cognitive costs. Limitations include the static nature of the model and the assumption of perfect machine accuracy.\",\n",
            "    \"Keywords\": \"machine-learning, rational inattention, human-machine collaboration, cognitive effort\",\n",
            "    \"Authors\": \"Tamer Boyaci, Caner Canyakmaz, Francis de Véricourt\",\n",
            "    \"Publication Information\": \"ESMT Working Paper 20-02, November 30, 2020\",\n",
            "    \"Article Name\": \"Human and Machine: The Impact of Machine Input on Decision-Making Under Cognitive Limitations\"\n",
            "}\n",
            "Summary added to the summaries list.\n",
            "\n",
            "Processing /content/papers/32 article/ssrn-4897619.pdf ...\n",
            "GPT Original Output: {\n",
            "    \"Context\": \"The study is focused on the broader, conceptual scope of AI in business research, covering various industries and applications.\",\n",
            "    \"Research Question and Findings\": \"The main research question is to synthesize existing literature on AI in business and provide a framework for understanding AI applications, human perceptions of AI, and AI behavior. The key findings include identifying five principal research questions and offering suggestions for future research directions.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"AI has achieved or surpassed human performance in several areas, such as Go, image recognition, and text annotation tasks. However, AI does not outperform humans in all aspects, and there are contexts where human curation excels.\",\n",
            "        \"Human + AI Collaboration\": \"The study discusses various types of collaboration, including AI as an assistant, collaborator, and competitor. It highlights the roles of humans and AI in decision-making processes and explores how they can work together to enhance productivity.\"\n",
            "    },\n",
            "    \"Method\": \"Conceptual/Case Study\",\n",
            "    \"Contribution\": \"Theoretical\",\n",
            "    \"Future Potential and Limitations\": \"The study suggests future research directions, including exploring the changes AI brings to industries, how humans and AI can collaborate, human perceptions of AI, identifying AI behaviors, and reducing AI bias. Limitations include not covering AI research in Economics, Psychology, and Social Science, and excluding recent studies due to the limited review period.\",\n",
            "    \"Keywords\": \"Artificial intelligence, human perception, human-AI interaction, algorithmic bias\",\n",
            "    \"Authors\": \"Zhi Cao, Meng Li, Paul A Pavlou\",\n",
            "    \"Publication Information\": \"The article is published in a journal covering AI in business research, with a focus on literature from 2010 to 2023.\",\n",
            "    \"Article Name\": \"AI in Business Research\"\n",
            "}\n",
            "Extracted Information:\n",
            "{\n",
            "    \"Context\": \"The study is focused on the broader, conceptual scope of AI in business research, covering various industries and applications.\",\n",
            "    \"Research Question and Findings\": \"The main research question is to synthesize existing literature on AI in business and provide a framework for understanding AI applications, human perceptions of AI, and AI behavior. The key findings include identifying five principal research questions and offering suggestions for future research directions.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"AI has achieved or surpassed human performance in several areas, such as Go, image recognition, and text annotation tasks. However, AI does not outperform humans in all aspects, and there are contexts where human curation excels.\",\n",
            "        \"Human + AI Collaboration\": \"The study discusses various types of collaboration, including AI as an assistant, collaborator, and competitor. It highlights the roles of humans and AI in decision-making processes and explores how they can work together to enhance productivity.\"\n",
            "    },\n",
            "    \"Method\": \"Conceptual/Case Study\",\n",
            "    \"Contribution\": \"Theoretical\",\n",
            "    \"Future Potential and Limitations\": \"The study suggests future research directions, including exploring the changes AI brings to industries, how humans and AI can collaborate, human perceptions of AI, identifying AI behaviors, and reducing AI bias. Limitations include not covering AI research in Economics, Psychology, and Social Science, and excluding recent studies due to the limited review period.\",\n",
            "    \"Keywords\": \"Artificial intelligence, human perception, human-AI interaction, algorithmic bias\",\n",
            "    \"Authors\": \"Zhi Cao, Meng Li, Paul A Pavlou\",\n",
            "    \"Publication Information\": \"The article is published in a journal covering AI in business research, with a focus on literature from 2010 to 2023.\",\n",
            "    \"Article Name\": \"AI in Business Research\"\n",
            "}\n",
            "Summary added to the summaries list.\n",
            "\n",
            "Processing /content/papers/32 article/J of Ops Management - 2024 - Amaya - Using algorithms to improve knowledge work.pdf ...\n",
            "GPT Original Output: {\n",
            "    \"Context\": \"The study is focused on the energy industry, specifically on improving knowledge work in a multinational energy firm undergoing digital transformation.\",\n",
            "    \"Research Question and Findings\": \"The main research question is how organizations can adopt algorithmic solutions to create and sustain improvements in knowledge-intensive tasks that require skilled work. The key findings indicate that both task automation and process re-engineering pathways can improve knowledge work, with process re-engineering yielding greater operational improvements.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"The study challenges the notion that tasks requiring skilled work cannot benefit from algorithms, showing that even creative and socially intelligent tasks can be improved with algorithmic solutions.\",\n",
            "        \"Human + AI Collaboration\": \"The study discusses two types of collaboration: automating specific tasks with algorithms and re-engineering entire processes to integrate algorithms, highlighting the importance of aligning tasks with the chosen pathway.\"\n",
            "    },\n",
            "    \"Method\": \"Conceptual/Case Study\",\n",
            "    \"Contribution\": \"Theoretical\",\n",
            "    \"Future Potential and Limitations\": \"The study suggests future research should explore additional pathways, practices, and outcomes associated with algorithm adoption in diverse contexts. Limitations include the focus on specific knowledge practices and skill requirements, without examining other factors like status or organization type.\",\n",
            "    \"Keywords\": \"future of work, knowledge work, machine learning, process improvement, robotic process automation\",\n",
            "    \"Authors\": \"Javier Amaya, Matthias Holweg\",\n",
            "    \"Publication Information\": \"Journal of Operations Management, 2024, Pages 482-513, DOI: 10.1002/joom.1296\",\n",
            "    \"Article Name\": \"Using algorithms to improve knowledge work\"\n",
            "}\n",
            "Extracted Information:\n",
            "{\n",
            "    \"Context\": \"The study is focused on the energy industry, specifically on improving knowledge work in a multinational energy firm undergoing digital transformation.\",\n",
            "    \"Research Question and Findings\": \"The main research question is how organizations can adopt algorithmic solutions to create and sustain improvements in knowledge-intensive tasks that require skilled work. The key findings indicate that both task automation and process re-engineering pathways can improve knowledge work, with process re-engineering yielding greater operational improvements.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"The study challenges the notion that tasks requiring skilled work cannot benefit from algorithms, showing that even creative and socially intelligent tasks can be improved with algorithmic solutions.\",\n",
            "        \"Human + AI Collaboration\": \"The study discusses two types of collaboration: automating specific tasks with algorithms and re-engineering entire processes to integrate algorithms, highlighting the importance of aligning tasks with the chosen pathway.\"\n",
            "    },\n",
            "    \"Method\": \"Conceptual/Case Study\",\n",
            "    \"Contribution\": \"Theoretical\",\n",
            "    \"Future Potential and Limitations\": \"The study suggests future research should explore additional pathways, practices, and outcomes associated with algorithm adoption in diverse contexts. Limitations include the focus on specific knowledge practices and skill requirements, without examining other factors like status or organization type.\",\n",
            "    \"Keywords\": \"future of work, knowledge work, machine learning, process improvement, robotic process automation\",\n",
            "    \"Authors\": \"Javier Amaya, Matthias Holweg\",\n",
            "    \"Publication Information\": \"Journal of Operations Management, 2024, Pages 482-513, DOI: 10.1002/joom.1296\",\n",
            "    \"Article Name\": \"Using algorithms to improve knowledge work\"\n",
            "}\n",
            "Summary added to the summaries list.\n",
            "\n",
            "Processing /content/papers/32 article/retrieve-5.pdf ...\n",
            "Error reading /content/papers/32 article/retrieve-5.pdf: '/Kids'\n",
            "Unable to process /content/papers/32 article/retrieve-5.pdf due to extraction issues.\n",
            "\n",
            "Processing /content/papers/32 article/bauer-et-al-2023-expl%28ai%29ned-the-impact-of-explainable-artificial-intelligence-on-users-information-processing.pdf ...\n",
            "GPT Original Output: {\n",
            "    \"Context\": \"The study focuses on the impact of explainable AI (XAI) on users' information processing in the context of investment decisions and real estate price estimation.\",\n",
            "    \"Research Question and Findings\": \"The main research questions are: Does the provision of feature-based explanations affect AI system users' situational processing of observed information? Does it affect users' underlying mental models? What are important moderating factors? The key findings indicate that explanations change users' situational weighting of available information and evoke mental model adjustments, which are subject to confirmation bias, leading to potential suboptimal or biased decisions.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"The study highlights that providing predictions alone is insufficient for knowledge transfer from AI to humans. Explanations are necessary for users to adjust their mental models according to AI logic.\",\n",
            "        \"Human + AI Collaboration\": \"The research discusses how explanations enable AI systems to influence human cognitive processes, potentially leading to improved decision-making if explanations align with users' mental models.\"\n",
            "    },\n",
            "    \"Method\": \"Empirical Research (laboratory/field experiments)\",\n",
            "    \"Contribution\": \"Theoretical and methodological contribution by identifying the cognitive effects of XAI on users' information processing and mental models.\",\n",
            "    \"Future Potential and Limitations\": \"Future research should explore the role of feedback in XAI interactions and examine different forms of explanations. Limitations include the lack of feedback on decision outcomes and the focus on local, feature-based XAI methods.\",\n",
            "    \"Keywords\": \"explainable artificial intelligence, user behavior, information processing, mental models\",\n",
            "    \"Authors\": \"Kevin Bauer, Moritz von Zahn, Oliver Hinz\",\n",
            "    \"Publication Information\": \"Information Systems Research, Vol. 34, No. 4, December 2023, pp. 1582–1602\",\n",
            "    \"Article Name\": \"Expl(AI)ned: The Impact of Explainable Artificial Intelligence on Users’ Information Processing\"\n",
            "}\n",
            "Extracted Information:\n",
            "{\n",
            "    \"Context\": \"The study focuses on the impact of explainable AI (XAI) on users' information processing in the context of investment decisions and real estate price estimation.\",\n",
            "    \"Research Question and Findings\": \"The main research questions are: Does the provision of feature-based explanations affect AI system users' situational processing of observed information? Does it affect users' underlying mental models? What are important moderating factors? The key findings indicate that explanations change users' situational weighting of available information and evoke mental model adjustments, which are subject to confirmation bias, leading to potential suboptimal or biased decisions.\",\n",
            "    \"Theme of Research\": {\n",
            "        \"Human vs AI\": \"The study highlights that providing predictions alone is insufficient for knowledge transfer from AI to humans. Explanations are necessary for users to adjust their mental models according to AI logic.\",\n",
            "        \"Human + AI Collaboration\": \"The research discusses how explanations enable AI systems to influence human cognitive processes, potentially leading to improved decision-making if explanations align with users' mental models.\"\n",
            "    },\n",
            "    \"Method\": \"Empirical Research (laboratory/field experiments)\",\n",
            "    \"Contribution\": \"Theoretical and methodological contribution by identifying the cognitive effects of XAI on users' information processing and mental models.\",\n",
            "    \"Future Potential and Limitations\": \"Future research should explore the role of feedback in XAI interactions and examine different forms of explanations. Limitations include the lack of feedback on decision outcomes and the focus on local, feature-based XAI methods.\",\n",
            "    \"Keywords\": \"explainable artificial intelligence, user behavior, information processing, mental models\",\n",
            "    \"Authors\": \"Kevin Bauer, Moritz von Zahn, Oliver Hinz\",\n",
            "    \"Publication Information\": \"Information Systems Research, Vol. 34, No. 4, December 2023, pp. 1582–1602\",\n",
            "    \"Article Name\": \"Expl(AI)ned: The Impact of Explainable Artificial Intelligence on Users’ Information Processing\"\n",
            "}\n",
            "Summary added to the summaries list.\n",
            "\n",
            "All summaries have been saved to /content/summaries.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***The demo and summary for Function1 are executed here. Please ensure that all prior tasks are completed in sequence up to this point to facilitate a smooth process.***\n"
      ],
      "metadata": {
        "id": "l_N3w7HFTfZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "\n",
        "# Define the path to summaries.json\n",
        "summaries_file_path = '/content/summaries.json'\n",
        "\n",
        "# Load summaries.json\n",
        "# Load summaries.json\n",
        "try:\n",
        "    with open(summaries_file_path, 'r', encoding='utf-8') as f:\n",
        "        summaries = json.load(f)\n",
        "except FileNotFoundError:\n",
        "    print(f\"File not found: {summaries_file_path}\")\n",
        "    summaries = []\n",
        "\n",
        "# Define a function to find summaries by a specific author\n",
        "def find_summary_by_author(author_keyword):\n",
        "    matched_summaries = []\n",
        "    for summary in summaries:\n",
        "        authors = summary['summary'].get('Authors', '')\n",
        "        # Use regular expressions for more accurate author matching\n",
        "        if re.search(rf'\\b{re.escape(author_keyword)}\\b', authors, re.IGNORECASE):\n",
        "            matched_summaries.append(summary)\n",
        "    return matched_summaries\n",
        "\n",
        "# Find all summaries containing 'Gnewuch'\n",
        "gnewuch_summaries = find_summary_by_author('Gnewuch')\n",
        "\n",
        "if gnewuch_summaries:\n",
        "    print(f\"### Found {len(gnewuch_summaries)} summaries by 'Gnewuch':\\n\")\n",
        "    # Collect all summaries' content to integrate\n",
        "    combined_summary_content = \"\"\n",
        "    for idx, gnewuch_summary in enumerate(gnewuch_summaries, start=1):\n",
        "        print(f\"### Gnewuch et al. Summary {idx}:\")\n",
        "        print(json.dumps(gnewuch_summary['summary'], ensure_ascii=False, indent=4))\n",
        "        print(\"\\n---\\n\")\n",
        "        # Combine the summary content for AI processing\n",
        "        combined_summary_content += json.dumps(gnewuch_summary['summary'], ensure_ascii=False, indent=4) + \"\\n\"\n",
        "\n",
        "    # Define a function to generate an integrated summary using OpenAI's GPT\n",
        "    def generate_integrated_summary(content):\n",
        "        try:\n",
        "            response = openai.ChatCompletion.create(\n",
        "                model=\"gpt-4o\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant that summarizes academic research.\"},\n",
        "                    {\"role\": \"user\", \"content\": f\"Please create a comprehensive summary based on the following content:\\n\\n{content}\"}\n",
        "                ],\n",
        "                max_tokens = 10000,\n",
        "                temperature = 0.3,\n",
        "            )\n",
        "            return response.choices[0].message['content'].strip()\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred while generating the summary: {e}\")\n",
        "            return None\n",
        "\n",
        "    # Generate the integrated summary\n",
        "    integrated_summary = generate_integrated_summary(combined_summary_content)\n",
        "\n",
        "    if integrated_summary:\n",
        "        print(\"### Integrated Summary Generated by AI:\\n\")\n",
        "        print(integrated_summary)\n",
        "    else:\n",
        "        print(\"Failed to generate the integrated summary.\")\n",
        "else:\n",
        "    print(\"No summaries containing 'Gnewuch' were found. Please check the file naming and Authors field format.\")\n",
        "\n",
        "# Initialize counters\n",
        "conceptual_count = 0\n",
        "modeling_count = 0\n",
        "empirical_count = 0\n",
        "\n",
        "experiments_count = 0\n",
        "secondary_data_count = 0\n",
        "\n",
        "# Iterate through all summaries and count\n",
        "for summary in summaries:\n",
        "    method = summary['summary'].get('Method', '').lower()\n",
        "\n",
        "    if 'conceptual' in method or 'case study' in method:\n",
        "        conceptual_count += 1\n",
        "    if 'modeling' in method:\n",
        "        modeling_count += 1\n",
        "    if 'empirical' in method:\n",
        "        empirical_count += 1\n",
        "        # Further categorize empirical research\n",
        "        if 'experiment' in method:\n",
        "            experiments_count += 1\n",
        "        if 'secondary data' in method or 'secondary data analysis' in method:\n",
        "            secondary_data_count += 1\n",
        "\n",
        "# Print the counting results\n",
        "print(\"\\n### Research Methods Count in 32 Papers:\")\n",
        "print(f\"- Conceptual Studies: {conceptual_count} papers\")\n",
        "print(f\"- Modeling Studies: {modeling_count} papers\")\n",
        "print(f\"- Empirical Studies: {empirical_count} papers\")\n",
        "\n",
        "print(\"\\n### Within Empirical Studies:\")\n",
        "print(f\"- Experiments: {experiments_count} papers\")\n",
        "print(f\"- Secondary Data Analysis: {secondary_data_count} papers\")\n",
        "\n",
        "# **Additional Summary Statement**\n",
        "print(\"\\n### Summary Statement:\")\n",
        "print(f\"Among the 32 papers, {conceptual_count} are conceptual studies, {modeling_count} are modeling studies (either stylized or OR models), and {empirical_count} are empirical studies. Of the empirical studies, {experiments_count} are experiments, and {secondary_data_count} use secondary data analysis.\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "rtsw7dDh_G2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Function 2 Demo***"
      ],
      "metadata": {
        "id": "gJBBNI97BY1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import openai\n",
        "\n",
        "# Define the path to summaries.json\n",
        "summaries_file_path = '/content/summaries.json'\n",
        "\n",
        "# Load summaries.json\n",
        "def load_summaries(file_path):\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            return json.load(f)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"File not found: {file_path}\")\n",
        "        return []\n",
        "\n",
        "# Filter function\n",
        "def simple_filter_summaries(summaries, theme_keyword, method_keyword):\n",
        "    \"\"\"\n",
        "    Filters summaries to include only those that contain the specified theme keyword and method keyword.\n",
        "\n",
        "    Parameters:\n",
        "        summaries (list): List of all literature summaries.\n",
        "        theme_keyword (str): Theme keyword, e.g., 'Human vs AI'.\n",
        "        method_keyword (str): Method keyword, e.g., 'Empirical Research'.\n",
        "\n",
        "    Returns:\n",
        "        list: Filtered list of literature summaries.\n",
        "    \"\"\"\n",
        "    filtered = []\n",
        "    for summary in summaries:\n",
        "        theme_of_research = summary['summary'].get('Theme of Research', {})\n",
        "        method = summary['summary'].get('Method', '').lower()\n",
        "\n",
        "        # Check if the specified theme keyword exists in the theme keys\n",
        "        has_theme = theme_keyword.lower() in (key.lower() for key in theme_of_research.keys())\n",
        "\n",
        "        # Check if the method field contains the specified keyword\n",
        "        has_method = method_keyword.lower() in method\n",
        "\n",
        "        if has_theme and has_method:\n",
        "            filtered.append(summary)\n",
        "    return filtered\n",
        "\n",
        "# Generate literature review function\n",
        "def generate_literature_review(filtered_summaries):\n",
        "    \"\"\"\n",
        "    Generates a literature review and reference list based on the filtered summaries.\n",
        "\n",
        "    Parameters:\n",
        "        filtered_summaries (list): List of filtered literature summaries.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    if not filtered_summaries:\n",
        "        print(\"No articles meet the criteria.\")\n",
        "        return\n",
        "\n",
        "    compiled_content = \"\"\n",
        "    reference_list = []\n",
        "    for summary in filtered_summaries:\n",
        "        compiled_content += json.dumps(summary['summary'], ensure_ascii=False, indent=4) + \"\\n\"\n",
        "        title = summary['summary'].get('Article Name', 'Title Missing')\n",
        "        authors = summary['summary'].get('Authors', 'Authors Missing')\n",
        "        publication_info = summary['summary'].get('Publication Information', 'Journal/Conference Missing')\n",
        "        if ',' in publication_info:\n",
        "            parts = publication_info.split(',')\n",
        "            journal = parts[0].strip()\n",
        "            year = parts[1].strip() if len(parts) > 1 else 'Year Missing'\n",
        "        else:\n",
        "            journal = publication_info.strip()\n",
        "            year = 'Year Missing'\n",
        "        reference = f\"{authors}. ({year}). {title}. {journal}.\"\n",
        "        reference_list.append(reference)\n",
        "\n",
        "    # Adjusted prompt to emphasize narrative style and natural citation integration\n",
        "    prompt = (\n",
        "        \"You are an assistant proficient in writing academic literature reviews. \"\n",
        "        \"Based on the following content, please write a comprehensive and cohesive literature review that seamlessly integrates the provided studies. \"\n",
        "        \"Discuss the connections, common themes, trends, and future directions of the research in a narrative format without using bullet points or separate sections. \"\n",
        "        \"Ensure that all references are cited appropriately within the text using APA in-text citations.\\n\\n\"\n",
        "        f\"{compiled_content}\"\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-4o\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a knowledgeable assistant skilled in writing academic literature reviews.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            max_tokens=15000,\n",
        "            temperature=0.5,\n",
        "        )\n",
        "        literature_review = response.choices[0].message['content'].strip()\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating literature review: {e}\")\n",
        "        return\n",
        "\n",
        "    if literature_review:\n",
        "        # Format the reference list (APA style)\n",
        "        formatted_references = \"\\n\".join([f\"{idx + 1}. {ref}\" for idx, ref in enumerate(reference_list)])\n",
        "        full_review = f\"{literature_review}\\n\\n### References:\\n{formatted_references}\"\n",
        "        print(full_review)\n",
        "    else:\n",
        "        print(\"Failed to generate literature review.\")\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    summaries = load_summaries(summaries_file_path)\n",
        "    theme_keyword = 'Human vs AI'\n",
        "    method_keyword = 'Empirical Research'\n",
        "    filtered = simple_filter_summaries(summaries, theme_keyword, method_keyword)\n",
        "\n",
        "    if not filtered:\n",
        "        print(\"No articles meet the criteria.\")\n",
        "        return\n",
        "\n",
        "    generate_literature_review(filtered)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "NgO-dDnEHBt3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}